{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f37b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.05568393154626\n"
     ]
    }
   ],
   "source": [
    "a=[78.33,70.13,69.56,49.07,26.83]\n",
    "b=[16229,27413,16096,4157,68167]\n",
    "total=0.0\n",
    "for i,num in enumerate(a):\n",
    "    total+=num*b[i]\n",
    "print (total/132060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbb064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5481ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "VQA_PATH='/Data_Storage/Rui_Data_Space/multimodal/VQA'\n",
    "GQA_PATH='/Data_Storage/Rui_Data_Space/multimodal/GQA'\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def load_pkl(path):\n",
    "    data=pkl.load(open(path,'rb'))\n",
    "    return data\n",
    "\n",
    "def load_json(path):\n",
    "    data=json.load(open(path,'r'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c7360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE=15\n",
    "torch.cuda.set_device(CUDA_DEVICE)\n",
    "device = torch.device(\"cuda:\"+str(CUDA_DEVICE))\n",
    "#the default ipykernel links to the first conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6e370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/nlp-rui/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-large')\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f8c6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.sep_token = '</s>'\n",
    "t5_model = t5_model.to(device)\n",
    "t5_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddcf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token_mapping = {'cls': t5_tokenizer.cls_token_id,\n",
    "                         'mask': t5_tokenizer.mask_token_id,\n",
    "                         'sep': t5_tokenizer.sep_token_id, \n",
    "                         'sep+': t5_tokenizer.sep_token_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79a5b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls None\n",
      "mask None\n",
      "sep 1\n",
      "sep+ 1\n",
      "<extra_id_0> 32099\n",
      "<extra_id_1> 32098\n",
      "<extra_id_2> 32097\n",
      "<extra_id_3> 32096\n",
      "<extra_id_4> 32095\n",
      "<extra_id_5> 32094\n",
      "<extra_id_6> 32093\n",
      "<extra_id_7> 32092\n",
      "<extra_id_8> 32091\n",
      "<extra_id_9> 32090\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    special_token_mapping[\"<extra_id_%d>\" % (i)] = \\\n",
    "    t5_tokenizer._convert_token_to_id(\"<extra_id_%d>\" % (i))\n",
    "for w in special_token_mapping:\n",
    "    print (w,special_token_mapping[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf4f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(text):\n",
    "    return t5_tokenizer.encode(text, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text='the <extra_id_0> is on the man\\'s back.'\n",
    "tokens=enc(input_text)\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949d74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC_MAX_LEN=20\n",
    "DEC_MAX_LEN=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors = [torch.tensor(tokens).long()]\n",
    "max_length = max(ENC_MAX_LEN, len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.zeros((len(input_tensors), max_length)).long()\n",
    "attention_mask = torch.zeros((len(input_tensors), max_length)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(input_tensors)):\n",
    "    input_ids[i, :input_tensors[i].size(-1)] = input_tensors[i]\n",
    "    attention_mask[i, :input_tensors[i].size(-1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t5_tokenizer.decode(input_ids[0]))\n",
    "print (input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcebf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.cuda()\n",
    "attention_mask = attention_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a964b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mask = t5_tokenizer._convert_token_to_id('<extra_id_0>')\n",
    "ori_decoder_input_ids = torch.zeros((input_ids.size(0), DEC_MAX_LEN)).long()\n",
    "ori_decoder_input_ids[..., 0] = t5_model.config.decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_output = [{'decoder_input_ids': ori_decoder_input_ids,\n",
    "                   'll': 0, 'output_id': 1, 'output': [], \n",
    "                   'last_length': -1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam=5\n",
    "target_number=2\n",
    "for i in range(max_length - 2):\n",
    "    print ('Current len:',i)\n",
    "    new_current_output = []\n",
    "    for item in current_output:\n",
    "        print ('\\tLength of current_output',len(current_output))\n",
    "        if item['output_id'] > target_number:\n",
    "            # Enough contents\n",
    "            new_current_output.append(item)\n",
    "            continue\n",
    "        decoder_input_ids = item['decoder_input_ids']\n",
    "\n",
    "        # Forward\n",
    "        batch_size = 32\n",
    "        turn = input_ids.size(0) // batch_size\n",
    "        if input_ids.size(0) % batch_size != 0:\n",
    "            turn += 1\n",
    "        aggr_output = []\n",
    "        for t in range(turn):\n",
    "            start = t * batch_size\n",
    "            end = min((t + 1) * batch_size, input_ids.size(0))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                aggr_output.append(t5_model(\n",
    "                    input_ids[start:end], \n",
    "                    attention_mask=attention_mask[start:end], \n",
    "                    decoder_input_ids=decoder_input_ids.cuda()[start:end])[0])\n",
    "        aggr_output = torch.cat(aggr_output, 0)\n",
    "\n",
    "        # Gather results across all input sentences, and sort generated tokens by log likelihood\n",
    "        aggr_output = aggr_output.mean(0)\n",
    "        log_denominator = torch.logsumexp(aggr_output[i], -1).item()\n",
    "        ids = list(range(t5_model.config.vocab_size))\n",
    "        ids.sort(key=lambda x: aggr_output[i][x].item(), reverse=True)\n",
    "        ids = ids[:beam+3]\n",
    "            \n",
    "        for k,word_id in enumerate(ids):\n",
    "            #print (k,'-th word')\n",
    "            output_id = item['output_id']\n",
    "\n",
    "            if word_id == start_mask - output_id or \\\n",
    "            word_id == t5_tokenizer._convert_token_to_id('</s>'):\n",
    "                # Finish one part\n",
    "                check = True\n",
    "                output_id += 1\n",
    "                last_length = 0\n",
    "            else:\n",
    "                last_length = item['last_length'] + 1\n",
    "                check = True\n",
    "\n",
    "            output_text = item['output'] + [word_id]\n",
    "            ll = item['ll'] + aggr_output[i][word_id] - log_denominator\n",
    "            new_decoder_input_ids = decoder_input_ids.new_zeros(decoder_input_ids.size())\n",
    "            new_decoder_input_ids[:] = decoder_input_ids\n",
    "            new_decoder_input_ids[..., i + 1] = word_id\n",
    "            \n",
    "            if word_id in [3, 19794, 22354]:\n",
    "                check = False\n",
    "\n",
    "            # Forbid continuous \".\"\n",
    "            if len(output_text) > 1 and output_text[-2] == 5 and output_text[-1] == 5:\n",
    "                check = False\n",
    "\n",
    "            if check:\n",
    "                # Add new results to beam search pool\n",
    "                new_item = {'decoder_input_ids': new_decoder_input_ids, 'll': ll, 'output_id': output_id, 'output': output_text, 'last_length': last_length}\n",
    "                new_current_output.append(new_item)\n",
    "    print ('One iteration finished...')\n",
    "    if len(new_current_output) == 0:\n",
    "        break\n",
    "\n",
    "    new_current_output.sort(key=lambda x: x['ll'], reverse=True)\n",
    "    new_current_output = new_current_output[:beam]\n",
    "    current_output = new_current_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "print(\"####### generated results #######\")\n",
    "for item in current_output:\n",
    "    generate_text = ''\n",
    "    for token in item['output']:\n",
    "        generate_text += t5_tokenizer._convert_id_to_token(token)\n",
    "    print('--------------')\n",
    "    print('score:', item['ll'].item())\n",
    "    print('generated ids', item['output'])\n",
    "    print('generated text', generate_text)\n",
    "    print (len(generate_text))\n",
    "    result.append(generate_text)\n",
    "print(\"####### generated results #######\\n\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9484e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = 'the <extra_id_0> is on the wall on the left.'\n",
    "\n",
    "encoded = t5_tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "# Generaing 20 sequences with maximum length set to 5\n",
    "outputs = t5_model.generate(input_ids=input_ids, \n",
    "                            num_beams=100, num_return_sequences=100,\n",
    "                            max_length=30)\n",
    "\n",
    "_0_index = text.index('<extra_id_0>')\n",
    "_result_prefix = text[:_0_index]\n",
    "_result_suffix = text[_0_index+20:]  # 12 is the length of <extra_id_0>\n",
    "\n",
    "def _filter(output, end_token='<extra_id_1>'):\n",
    "    # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
    "    _txt = t5_tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    #print (_txt)\n",
    "    text=_txt.replace('<extra_id_1>',' <s>')\n",
    "    #print (text)\n",
    "    text=text.replace('.',' <s>')\n",
    "    text=text.replace(',',' <s>')\n",
    "    result=text.split('<s>')[0].strip()\n",
    "    if '\\'s' in result:\n",
    "        result=result.replace('\\'s',' <s>')\n",
    "        #print (result)\n",
    "        return result.split('<s>')[1].strip()\n",
    "    return text.split('<s>')[0].strip()\n",
    "    \"\"\"if end_token in _txt:\n",
    "        _end_token_index = _txt.index(end_token)\n",
    "        return _result_prefix + _txt[:_end_token_index] + _result_suffix\n",
    "    else:\n",
    "        return _result_prefix + _txt + _result_suffix\"\"\"\n",
    "\n",
    "results = list(map(_filter, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc8bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_generator(text):\n",
    "    encoded = t5_tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "    # Generaing 20 sequences with maximum length set to 5\n",
    "    outputs = t5_model.generate(input_ids=input_ids, \n",
    "                                num_beams=50, num_return_sequences=30,\n",
    "                                max_length=30)\n",
    "    results = list(map(_filter, outputs))\n",
    "    results=list(set(results))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332c964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dd095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c317ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of testing data: 214354\n",
      "defaultdict(<class 'int'>, {'none of the above': 8550, 'what are the': 3282, 'what is': 6328, 'what': 15897, 'is this a': 7492, 'is this': 7841, 'what is the man': 2663, 'how many': 20462, 'what does the': 1970, 'why': 1438, 'is it': 3566, 'why is the': 514, 'what color is the': 14061, 'is there a': 4679, 'is the': 17265, 'is that a': 714, 'are these': 2839, 'are the': 5264, 'what is the': 11353, 'which': 2448, 'could': 618, 'are there': 2771, 'what kind of': 5840, 'has': 946, 'what color are the': 3118, 'are there any': 1330, 'is this person': 734, 'does the': 3183, 'where is the': 3716, 'how many people are': 2005, 'can you': 872, 'what type of': 4040, 'what is the color of the': 826, 'what is on the': 2174, 'does this': 2227, 'is this an': 890, 'who is': 1070, 'what is this': 1696, 'is there': 3120, 'are': 2359, 'what time': 1746, 'how': 2422, 'what is in the': 1733, 'do you': 724, 'what are': 1556, 'what sport is': 1086, 'what is the person': 900, 'is he': 1087, 'where are the': 1313, 'what brand': 935, 'what number is': 673, 'what color is': 1335, 'what is the woman': 853, 'what room is': 762, 'is': 3169, 'what color': 1428, 'is the woman': 992, 'are they': 1335, 'is the person': 794, 'is the man': 2511, 'what animal is': 833, 'what is the name': 780, 'was': 818, 'do': 1503, 'how many people are in': 905})\n"
     ]
    }
   ],
   "source": [
    "val_all=load_json(os.path.join(VQA_PATH,'scenes','val_all.json'))\n",
    "print ('Length of testing data:',len(val_all))\n",
    "q_types_dict=defaultdict(int)\n",
    "for row in val_all:\n",
    "    q_types_dict[row['q_type']]+=1\n",
    "print (q_types_dict)\n",
    "val_based_qt={q_t:[] for q_t in q_types_dict}\n",
    "for row in val_all:\n",
    "    val_based_qt[row['q_type']].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40119a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105600\n"
     ]
    }
   ],
   "source": [
    "qid_to_t5={}\n",
    "with open('../clip_vqa/other_filtered_T5_large.json') as other:\n",
    "    for line in other:\n",
    "        data = json.loads(line.strip())\n",
    "        qid_to_t5[data['qid']] = data\n",
    "print (len(qid_to_t5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48591ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statement(statement,ques):\n",
    "    sent=[]\n",
    "    \n",
    "    if 'doing' in ques[:-1]:\n",
    "        inplace='action'\n",
    "    elif 'color' in ques[:-1]:\n",
    "        inplace='color'\n",
    "    elif 'made of' in ques[:-1]:\n",
    "        inplace='material'\n",
    "    else:\n",
    "        inplace='item'\n",
    "            \n",
    "    flag=True\n",
    "    for w in statement.split(' '):\n",
    "        if w==inplace:\n",
    "            if flag:\n",
    "                sent.append('<extra_id_0>')\n",
    "                flag=False\n",
    "        else:\n",
    "            sent.append(w)\n",
    "    if flag:\n",
    "        sent.append('<extra_id_0>')\n",
    "    sent=' '.join(sent)+'.'\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2b5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_ans(gt,pred):\n",
    "    flag=False\n",
    "    in_list=[]\n",
    "    for w in gt:\n",
    "        if w in pred:\n",
    "            flag=True\n",
    "            in_list.append(w)\n",
    "    return flag,in_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66dfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter(output, end_token='<extra_id_1>'):\n",
    "    # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
    "    _txt = t5_tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    #print (_txt)\n",
    "    text=_txt.replace('<extra_id_1>',' <s>')\n",
    "    #print (text)\n",
    "    text=text.replace('.',' <s>')\n",
    "    text=text.replace(',',' <s>')\n",
    "    result=text.split('<s>')[0].strip()\n",
    "    if '\\'s' in result:\n",
    "        result=result.replace('\\'s',' <s>')\n",
    "        #print (result)\n",
    "        return result.split('<s>')[1].strip()\n",
    "    return text.split('<s>')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed79efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "en_dict=enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d284ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "removed_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5afc84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_words=list(removed_words)\n",
    "removed_words.extend(['am','is','are','was','were'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f220692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(words):\n",
    "    results=[]\n",
    "    for w in words:\n",
    "        if len(w)<=1:\n",
    "            continue\n",
    "        if w in ['\"\"',',','','.','?',':','??','(',')','-','/']:\n",
    "            continue\n",
    "        if w in ['<unk>','[unk]','unk']:\n",
    "            continue\n",
    "        if 'the' in w.split(' '):\n",
    "            w_list=[s for s in w.split(' ') if s !='the']\n",
    "            w=' '.join(w_list).lower()\n",
    "        elif 'this' in w.split(' '):\n",
    "            w_list=[s for s in w.split(' ') if s !='this']\n",
    "            w=' '.join(w_list).lower()\n",
    "        if w in removed_words:\n",
    "            continue\n",
    "        if w.isdigit():\n",
    "            continue\n",
    "        if len(w)>1 and en_dict.check(w):\n",
    "            results.append(w.lower())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51e43a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_generator(text):\n",
    "    encoded = t5_tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "\n",
    "    # Generaing 20 sequences with maximum length set to 5\n",
    "    outputs = t5_model.generate(input_ids=input_ids, \n",
    "                                num_beams=1000, num_return_sequences=350,\n",
    "                                max_length=3)\n",
    "    results = list(map(_filter, outputs))\n",
    "    results=list(set(results))\n",
    "    results=process(results)\n",
    "    results=list(set(results))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce90bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 09:04:12.493921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-29 09:04:12.493975: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['striking', 'encouraging', 'one', 'unchanged', 'poor', 'reasonable', 'shown', 'successful', 'beyond', 'outstanding', 'three', 'disappointing', 'minimal', 'insane', 'awkward', 'another', 'useless', 'like', 'normal', 'interesting', 'common', 'lacking', 'good', 'healthy', 'really', 'satisfactory', 'recommended', 'happening', 'stronger', 'allowed', 'ideal', 'ridiculous', 'included', 'disturbing', 'considered', 'stunning', 'free', 'unknown', 'frightening', 'worse', 'essential', 'significant', 'complicated', 'vital', 'suspicious', 'equal', 'prohibited', 'unexpected', 'extremely', 'identical', 'relevant', 'required', 'fascinating', 'illegal', 'achieved', 'clear', 'hard', 'inaccurate', 'satisfied', 'uncertain', 'huge', 'known', 'coming', 'superior', 'mentioned', 'close', 'strong', 'impressive', 'stated', 'unlikely', 'embarrassing', 'useful', 'confirmed', 'explained', 'involved', 'concerned', 'completed', 'confidential', 'closed', 'shocking', 'quite', 'terrifying', 'incomplete', 'used', 'paramount', 'missing', 'excellent', 'dead', 'working', 'okay', 'awesome', 'problematic', 'intimidating', 'evident', 'unacceptable', 'high', 'responsible', 'negative', 'small', 'curious', 'false', 'needed', 'fixed', 'true', 'critical', 'said', 'released', 'beautiful', 'taken', 'overwhelming', 'due', 'applicable', 'unique', 'optional', 'imperative', 'redundant', 'unclear', 'accurate', 'hilarious', 'fatal', 'empty', 'better', 'correct', 'present', 'presented', 'misleading', 'perfect', 'announced', 'challenging', 'expected', 'rare', 'valid', 'discussed', 'unavailable', 'done', 'completely', 'reduced', 'simple', 'related', 'well', 'made', 'voluntary', 'remarkable', 'lower', 'unusual', 'effective', 'much', 'wrong', 'new', 'dangerous', 'pretty', 'staggering', 'fine', 'easy', 'lost', 'added', 'safe', 'intriguing', 'sufficient', 'greater', 'listed', 'equally', 'enough', 'invaluable', 'surprising', 'available', 'odd', 'ok', 'beneficial', 'excessive', 'complete', 'ignored', 'welcome', 'real', 'displayed', 'possible', 'opposite', 'five', 'legal', 'split', 'confusing', 'substantial', 'called', 'positive', 'found', 'best', 'revealed', 'going', 'eliminated', 'likely', 'confused', 'right', 'unprecedented', 'two', 'higher', 'described', 'attractive', 'astonishing', 'controversial', 'fantastic', 'incredible', 'absurd', 'inevitable', 'determined', 'set', 'superb', 'bad', 'nice', 'next', 'different', 'straightforward', 'exceptional', 'mandatory', 'increasing', 'divided', 'difficult', 'provided', 'broken', 'appropriate', 'amazing', 'shared', 'key', 'considerable', 'similar', 'extraordinary', 'impossible', 'excluded', 'left', 'acceptable', 'unrealistic', 'unfortunate', 'obvious', 'necessary', 'low', 'balanced', 'also', 'limited', 'less', 'irrelevant', 'removed', 'helpful', 'terrible', 'zero', 'given', 'important', 'decided', 'inappropriate', 'increased', 'incorrect', 'changing', 'changed', 'inadequate', 'flawed', 'connected', 'still', 'great', 'worth', 'unnecessary', 'independent', 'gone', 'wonderful', 'crucial', 'daunting']\n"
     ]
    }
   ],
   "source": [
    "text='the two individuals riding is <extra_id_0>'\n",
    "results=candidate_generator(text)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50d478af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11353\n",
      "What is the colorful object? ['kite', 'yes', 'parachute'] 104796\n",
      "\t the colorful object is <extra_id_0> .\n",
      "\tMine:  308 False []\n",
      "\tOthers:  18 False []\n",
      "\n",
      "\n",
      "What is the purpose of the glasses worn by the man? ['safety', 'protection'] 449895\n",
      "\t the purpose of the glasses worn by the man is <extra_id_0> .\n",
      "\tMine:  292 True ['safety']\n",
      "\tOthers:  161 True ['safety', 'protection']\n",
      "\n",
      "\n",
      "What is the person's gender? ['male'] 127669\n",
      "\t the person's gender is <extra_id_0> .\n",
      "\tMine:  258 True ['male']\n",
      "\tOthers:  142 True ['male']\n",
      "\n",
      "\n",
      "What is the woman's holding? ['phone', 'umbrella', 'umbrella, camera'] 235017\n",
      "\t the woman's holding is <extra_id_0> .\n",
      "\tMine:  299 False []\n",
      "\tOthers:  137 True ['umbrella']\n",
      "\n",
      "\n",
      "What is the an wearing? ['sweater', '2 shirts', 'striped shirt', 'striped sweater', 'shirt'] 450282\n",
      "\t the an wearing is <extra_id_0> .\n",
      "\tMine:  268 False []\n",
      "\tOthers:  166 False []\n",
      "\n",
      "\n",
      "What is the statue holding? ['walking cane', 'stuffed animal', 'cane', 'stick', 'walking stick', 'gun', 'teddy bear'] 209763\n",
      "\t the statue is holding <extra_id_0> .\n",
      "\tMine:  243 False []\n",
      "\tOthers:  152 True ['cane', 'stick', 'teddy bear']\n",
      "\n",
      "\n",
      "What is the road surface? ['cement', 'black', 'asphalt', 'concrete', 'tarmac'] 265378\n",
      "\t the road surface is <extra_id_0> .\n",
      "\tMine:  317 True ['cement', 'black', 'asphalt', 'concrete']\n",
      "\tOthers:  177 True ['cement', 'black', 'asphalt', 'concrete', 'tarmac']\n",
      "\n",
      "\n",
      "What is the eye color? ['yellow', 'gold', 'yellow and black', 'golden'] 287649\n",
      "\t the eye color is <extra_id_0> .\n",
      "\tMine:  268 True ['yellow', 'gold', 'golden']\n",
      "\tOthers:  18 True ['yellow', 'gold']\n",
      "\n",
      "\n",
      "What is the cat lying on? ['pillow and blankets', 'pillow', 'bed', 'laundry'] 124116\n",
      "\t the cat is lying on <extra_id_0> .\n",
      "\tMine:  257 True ['pillow', 'bed']\n",
      "\tOthers:  174 True ['pillow', 'bed']\n",
      "\n",
      "\n",
      "What is the fence made of? ['wood', 'yes', 'wood & wire', 'wire', 'bobbed wire'] 57917\n",
      "\t the fence made of is <extra_id_0> .\n",
      "\tMine:  254 True ['wood', 'wire']\n",
      "\tOthers:  167 True ['wood', 'wire']\n",
      "\n",
      "\n",
      "Total: 11 \n",
      "\tUpper acc 54.54545454545455\n"
     ]
    }
   ],
   "source": [
    "q_t='what is the'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "    if vis>10:\n",
    "        break\n",
    "    if row['ans_type']!='other':\n",
    "        continue\n",
    "    if row['idx'] not in qid_to_t5:\n",
    "        continue\n",
    "        \n",
    "    gt_scores=row['scores']\n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \n",
    "    base_info=qid_to_t5[row['idx']]\n",
    "    statement=base_info['prompts'][0]\n",
    "    t5_pred=candidate_generator(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans(row['answer'],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "        \n",
    "    print (ques,answers,row['img_id'])\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    upper,in_list=verify_ans(row['answer'],base_info['labels'])\n",
    "    print ('\\tOthers: ',len(base_info['labels']),upper,in_list)\n",
    "    print (\n",
    "        #t5_pred,\n",
    "        '\\n')\n",
    "    img_id='COCO_val2014_'+str(row['img_id']).zfill(12)+'.jpg'\n",
    "    if vis%200==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eaa05d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 500 500\n",
      "\tMine acc: 62.2\n",
      "\tTheir acc: 83.4\n",
      "Already finished: 1000 1000\n",
      "\tMine acc: 62.8\n",
      "\tTheir acc: 84.3\n",
      "Already finished: 1500 1500\n",
      "\tMine acc: 63.6\n",
      "\tTheir acc: 85.4\n",
      "Already finished: 2000 2000\n",
      "\tMine acc: 63.15\n",
      "\tTheir acc: 85.3\n",
      "Already finished: 2500 2500\n",
      "\tMine acc: 63.56\n",
      "\tTheir acc: 85.68\n",
      "Already finished: 3000 3000\n",
      "\tMine acc: 63.6\n",
      "\tTheir acc: 85.6\n",
      "Already finished: 3500 3500\n",
      "\tMine acc: 63.4\n",
      "\tTheir acc: 85.45714285714286\n",
      "Already finished: 4000 4000\n",
      "\tMine acc: 62.925\n",
      "\tTheir acc: 85.375\n",
      "Already finished: 4500 4500\n",
      "\tMine acc: 63.2\n",
      "\tTheir acc: 85.62222222222222\n",
      "Already finished: 5000 5000\n",
      "\tMine acc: 62.78\n",
      "\tTheir acc: 85.44\n",
      "Already finished: 5500 5500\n",
      "\tMine acc: 62.763636363636365\n",
      "\tTheir acc: 85.41818181818182\n",
      "Already finished: 6000 6000\n",
      "\tMine acc: 62.916666666666664\n",
      "\tTheir acc: 85.76666666666667\n",
      "Already finished: 6500 6500\n",
      "\tMine acc: 62.95384615384615\n",
      "\tTheir acc: 85.8923076923077\n",
      "Already finished: 7000 7000\n",
      "\tMine acc: 62.628571428571426\n",
      "\tTheir acc: 85.88571428571429\n",
      "Already finished: 7500 7500\n",
      "\tMine acc: 62.92\n",
      "\tTheir acc: 86.13333333333334\n",
      "Already finished: 8000 8000\n",
      "\tMine acc: 62.875\n",
      "\tTheir acc: 86.175\n",
      "Already finished: 8500 8500\n",
      "\tMine acc: 63.11764705882353\n",
      "\tTheir acc: 86.12941176470588\n",
      "Already finished: 9000 9000\n",
      "\tMine acc: 63.15555555555556\n",
      "\tTheir acc: 86.02222222222223\n",
      "Already finished: 9500 9500\n",
      "\tMine acc: 63.01052631578948\n",
      "\tTheir acc: 85.96842105263158\n",
      "Already finished: 10000 10000\n",
      "\tMine acc: 62.84\n",
      "\tTheir acc: 85.88\n",
      "Already finished: 10500 10500\n",
      "\tMine acc: 63.114285714285714\n",
      "\tTheir acc: 85.96190476190476\n",
      "Already finished: 11000 11000\n",
      "\tMine acc: 63.2\n",
      "\tTheir acc: 85.94545454545455\n",
      "Already finished: 11500 11500\n",
      "\tMine acc: 63.23478260869565\n",
      "\tTheir acc: 85.93913043478261\n",
      "Already finished: 12000 12000\n",
      "\tMine acc: 63.2\n",
      "\tTheir acc: 86.01666666666667\n",
      "Already finished: 12500 12500\n",
      "\tMine acc: 63.048\n",
      "\tTheir acc: 85.968\n",
      "Already finished: 13000 13000\n",
      "\tMine acc: 63.03846153846154\n",
      "\tTheir acc: 86.0\n",
      "Already finished: 13500 13500\n",
      "\tMine acc: 63.01481481481481\n",
      "\tTheir acc: 86.05185185185185\n",
      "Already finished: 14000 14000\n",
      "\tMine acc: 62.957142857142856\n",
      "\tTheir acc: 85.97857142857143\n",
      "Already finished: 14500 14500\n",
      "\tMine acc: 62.96551724137931\n",
      "\tTheir acc: 85.8551724137931\n",
      "Already finished: 15000 15000\n",
      "\tMine acc: 62.86\n",
      "\tTheir acc: 85.75333333333333\n",
      "Already finished: 15500 15500\n",
      "\tMine acc: 62.8\n",
      "\tTheir acc: 85.7483870967742\n",
      "Already finished: 16000 16000\n",
      "\tMine acc: 62.8\n",
      "\tTheir acc: 85.7125\n",
      "Already finished: 16500 16500\n",
      "\tMine acc: 62.84848484848485\n",
      "\tTheir acc: 85.67272727272727\n",
      "Already finished: 17000 17000\n",
      "\tMine acc: 62.85294117647059\n",
      "\tTheir acc: 85.62352941176471\n",
      "Already finished: 17500 17500\n",
      "\tMine acc: 62.8\n",
      "\tTheir acc: 85.6\n",
      "Already finished: 18000 18000\n",
      "\tMine acc: 62.84444444444444\n",
      "\tTheir acc: 85.62777777777778\n",
      "Already finished: 18500 18500\n",
      "\tMine acc: 62.983783783783785\n",
      "\tTheir acc: 85.6972972972973\n",
      "Already finished: 19000 19000\n",
      "\tMine acc: 63.026315789473685\n",
      "\tTheir acc: 85.7\n",
      "Already finished: 19500 19500\n",
      "\tMine acc: 63.02564102564103\n",
      "\tTheir acc: 85.67179487179487\n",
      "Already finished: 20000 20000\n",
      "\tMine acc: 63.065\n",
      "\tTheir acc: 85.73\n",
      "Already finished: 20500 20500\n",
      "\tMine acc: 63.04390243902439\n",
      "\tTheir acc: 85.72682926829269\n",
      "Already finished: 21000 21000\n",
      "\tMine acc: 62.94285714285714\n",
      "\tTheir acc: 85.64761904761905\n",
      "Already finished: 21500 21500\n",
      "\tMine acc: 62.95813953488372\n",
      "\tTheir acc: 85.64651162790697\n",
      "Already finished: 22000 22000\n",
      "\tMine acc: 62.89545454545455\n",
      "\tTheir acc: 85.64090909090909\n",
      "Already finished: 22500 22500\n",
      "\tMine acc: 62.96\n",
      "\tTheir acc: 85.61777777777777\n",
      "Already finished: 23000 23000\n",
      "\tMine acc: 62.904347826086955\n",
      "\tTheir acc: 85.55652173913043\n",
      "Already finished: 23500 23500\n",
      "\tMine acc: 62.83404255319149\n",
      "\tTheir acc: 85.53191489361703\n",
      "Already finished: 24000 24000\n",
      "\tMine acc: 62.770833333333336\n",
      "\tTheir acc: 85.5\n",
      "Already finished: 24500 24500\n",
      "\tMine acc: 62.78367346938776\n",
      "\tTheir acc: 85.46530612244898\n",
      "Already finished: 25000 25000\n",
      "\tMine acc: 62.804\n",
      "\tTheir acc: 85.464\n",
      "Already finished: 25500 25500\n",
      "\tMine acc: 62.8078431372549\n",
      "\tTheir acc: 85.50980392156863\n",
      "Already finished: 26000 26000\n",
      "\tMine acc: 62.75\n",
      "\tTheir acc: 85.52692307692308\n",
      "Already finished: 26500 26500\n",
      "\tMine acc: 62.73207547169811\n",
      "\tTheir acc: 85.51320754716981\n",
      "Already finished: 27000 27000\n",
      "\tMine acc: 62.72962962962963\n",
      "\tTheir acc: 85.54444444444445\n",
      "Already finished: 27500 27500\n",
      "\tMine acc: 62.74909090909091\n",
      "\tTheir acc: 85.56727272727272\n",
      "Already finished: 28000 28000\n",
      "\tMine acc: 62.80714285714286\n",
      "\tTheir acc: 85.60357142857143\n",
      "Already finished: 28500 28500\n",
      "\tMine acc: 62.83157894736842\n",
      "\tTheir acc: 85.59298245614035\n",
      "Already finished: 29000 29000\n",
      "\tMine acc: 62.793103448275865\n",
      "\tTheir acc: 85.55172413793103\n",
      "Already finished: 29500 29500\n",
      "\tMine acc: 62.77627118644068\n",
      "\tTheir acc: 85.56271186440678\n",
      "Already finished: 30000 30000\n",
      "\tMine acc: 62.776666666666664\n",
      "\tTheir acc: 85.56666666666666\n",
      "Already finished: 30500 30500\n",
      "\tMine acc: 62.79672131147541\n",
      "\tTheir acc: 85.57704918032788\n",
      "Already finished: 31000 31000\n",
      "\tMine acc: 62.83225806451613\n",
      "\tTheir acc: 85.59677419354838\n",
      "Already finished: 31500 31500\n",
      "\tMine acc: 62.8063492063492\n",
      "\tTheir acc: 85.58095238095238\n",
      "Already finished: 32000 32000\n",
      "\tMine acc: 62.81875\n",
      "\tTheir acc: 85.575\n",
      "Already finished: 32500 32500\n",
      "\tMine acc: 62.79692307692308\n",
      "\tTheir acc: 85.56\n",
      "Already finished: 33000 33000\n",
      "\tMine acc: 62.84848484848485\n",
      "\tTheir acc: 85.60909090909091\n",
      "Already finished: 33500 33500\n",
      "\tMine acc: 62.84776119402985\n",
      "\tTheir acc: 85.58507462686568\n",
      "Already finished: 34000 34000\n",
      "\tMine acc: 62.83529411764706\n",
      "\tTheir acc: 85.58823529411765\n",
      "Already finished: 34500 34500\n",
      "\tMine acc: 62.81739130434783\n",
      "\tTheir acc: 85.60579710144927\n",
      "Already finished: 35000 35000\n",
      "\tMine acc: 62.817142857142855\n",
      "\tTheir acc: 85.65142857142857\n",
      "Already finished: 35500 35500\n",
      "\tMine acc: 62.819718309859155\n",
      "\tTheir acc: 85.6225352112676\n",
      "Already finished: 36000 36000\n",
      "\tMine acc: 62.791666666666664\n",
      "\tTheir acc: 85.59722222222223\n",
      "Already finished: 36500 36500\n",
      "\tMine acc: 62.827397260273976\n",
      "\tTheir acc: 85.61369863013698\n",
      "Already finished: 37000 37000\n",
      "\tMine acc: 62.87027027027027\n",
      "\tTheir acc: 85.62702702702703\n",
      "Already finished: 37500 37500\n",
      "\tMine acc: 62.91466666666667\n",
      "\tTheir acc: 85.64\n",
      "Already finished: 38000 38000\n",
      "\tMine acc: 62.90263157894737\n",
      "\tTheir acc: 85.63947368421053\n",
      "Already finished: 38500 38500\n",
      "\tMine acc: 62.9038961038961\n",
      "\tTheir acc: 85.64675324675325\n",
      "Already finished: 39000 39000\n",
      "\tMine acc: 62.92564102564103\n",
      "\tTheir acc: 85.62820512820512\n",
      "Already finished: 39500 39500\n",
      "\tMine acc: 62.91898734177215\n",
      "\tTheir acc: 85.67848101265822\n",
      "Already finished: 40000 40000\n",
      "\tMine acc: 62.92\n",
      "\tTheir acc: 85.695\n",
      "Already finished: 40500 40500\n",
      "\tMine acc: 62.93333333333333\n",
      "\tTheir acc: 85.72345679012345\n",
      "Already finished: 41000 41000\n",
      "\tMine acc: 62.96341463414634\n",
      "\tTheir acc: 85.72195121951219\n",
      "Already finished: 41500 41500\n",
      "\tMine acc: 62.971084337349396\n",
      "\tTheir acc: 85.7132530120482\n",
      "Already finished: 42000 42000\n",
      "\tMine acc: 62.95952380952381\n",
      "\tTheir acc: 85.73333333333333\n",
      "Already finished: 42500 42500\n",
      "\tMine acc: 62.96\n",
      "\tTheir acc: 85.74823529411765\n",
      "Already finished: 43000 43000\n",
      "\tMine acc: 62.96046511627907\n",
      "\tTheir acc: 85.75348837209302\n",
      "Already finished: 43500 43500\n",
      "\tMine acc: 62.96781609195402\n",
      "\tTheir acc: 85.71724137931035\n",
      "Already finished: 44000 44000\n",
      "\tMine acc: 62.97727272727273\n",
      "\tTheir acc: 85.69318181818181\n",
      "Already finished: 44500 44500\n",
      "\tMine acc: 62.975280898876406\n",
      "\tTheir acc: 85.6561797752809\n",
      "Already finished: 45000 45000\n",
      "\tMine acc: 62.98222222222222\n",
      "\tTheir acc: 85.66888888888889\n",
      "Already finished: 45500 45500\n",
      "\tMine acc: 62.97142857142857\n",
      "\tTheir acc: 85.65494505494506\n",
      "Already finished: 46000 46000\n",
      "\tMine acc: 62.915217391304346\n",
      "\tTheir acc: 85.6304347826087\n",
      "Already finished: 46500 46500\n",
      "\tMine acc: 62.92688172043011\n",
      "\tTheir acc: 85.64731182795698\n",
      "Already finished: 47000 47000\n",
      "\tMine acc: 62.89787234042553\n",
      "\tTheir acc: 85.62340425531914\n",
      "Already finished: 47500 47500\n",
      "\tMine acc: 62.86736842105263\n",
      "\tTheir acc: 85.5957894736842\n",
      "Already finished: 48000 48000\n",
      "\tMine acc: 62.87291666666667\n",
      "\tTheir acc: 85.58125\n",
      "Already finished: 48500 48500\n",
      "\tMine acc: 62.83711340206185\n",
      "\tTheir acc: 85.56494845360825\n",
      "Already finished: 49000 49000\n",
      "\tMine acc: 62.8469387755102\n",
      "\tTheir acc: 85.57755102040817\n",
      "Already finished: 49500 49500\n",
      "\tMine acc: 62.85656565656566\n",
      "\tTheir acc: 85.58383838383838\n",
      "Already finished: 50000 50000\n",
      "\tMine acc: 62.856\n",
      "\tTheir acc: 85.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 50500 50500\n",
      "\tMine acc: 62.883168316831686\n",
      "\tTheir acc: 85.59207920792079\n",
      "Already finished: 51000 51000\n",
      "\tMine acc: 62.89411764705882\n",
      "\tTheir acc: 85.58039215686274\n",
      "Already finished: 51500 51500\n",
      "\tMine acc: 62.91067961165049\n",
      "\tTheir acc: 85.57281553398059\n",
      "Already finished: 52000 52000\n",
      "\tMine acc: 62.9\n",
      "\tTheir acc: 85.57692307692308\n",
      "Already finished: 52500 52500\n",
      "\tMine acc: 62.89904761904762\n",
      "\tTheir acc: 85.54857142857144\n",
      "Already finished: 53000 53000\n",
      "\tMine acc: 62.90188679245283\n",
      "\tTheir acc: 85.53018867924528\n",
      "Already finished: 53500 53500\n",
      "\tMine acc: 62.904672897196264\n",
      "\tTheir acc: 85.53084112149533\n",
      "Already finished: 54000 54000\n",
      "\tMine acc: 62.912962962962965\n",
      "\tTheir acc: 85.52592592592593\n",
      "Already finished: 54500 54500\n",
      "\tMine acc: 62.88073394495413\n",
      "\tTheir acc: 85.5137614678899\n",
      "Already finished: 55000 55000\n",
      "\tMine acc: 62.876363636363635\n",
      "\tTheir acc: 85.52\n",
      "Already finished: 55500 55500\n",
      "\tMine acc: 62.863063063063066\n",
      "\tTheir acc: 85.52072072072072\n",
      "Already finished: 56000 56000\n",
      "\tMine acc: 62.85357142857143\n",
      "\tTheir acc: 85.51964285714286\n",
      "Already finished: 56500 56500\n",
      "\tMine acc: 62.876106194690266\n",
      "\tTheir acc: 85.54159292035398\n",
      "Already finished: 57000 57000\n",
      "\tMine acc: 62.85964912280702\n",
      "\tTheir acc: 85.54912280701754\n",
      "Already finished: 57500 57500\n",
      "\tMine acc: 62.86260869565218\n",
      "\tTheir acc: 85.54782608695652\n",
      "Already finished: 58000 58000\n",
      "\tMine acc: 62.87068965517241\n",
      "\tTheir acc: 85.54482758620689\n",
      "Already finished: 58500 58500\n",
      "\tMine acc: 62.86153846153846\n",
      "\tTheir acc: 85.55384615384615\n",
      "Already finished: 59000 59000\n",
      "\tMine acc: 62.85762711864407\n",
      "\tTheir acc: 85.54745762711865\n",
      "Already finished: 59500 59500\n",
      "\tMine acc: 62.84705882352941\n",
      "\tTheir acc: 85.55798319327731\n",
      "Already finished: 60000 60000\n",
      "\tMine acc: 62.82\n",
      "\tTheir acc: 85.56333333333333\n",
      "Already finished: 60500 60500\n",
      "\tMine acc: 62.83140495867769\n",
      "\tTheir acc: 85.55371900826447\n",
      "Already finished: 61000 61000\n",
      "\tMine acc: 62.834426229508196\n",
      "\tTheir acc: 85.5688524590164\n",
      "Already finished: 61500 61500\n",
      "\tMine acc: 62.80813008130081\n",
      "\tTheir acc: 85.54471544715447\n",
      "Already finished: 62000 62000\n",
      "\tMine acc: 62.788709677419355\n",
      "\tTheir acc: 85.53709677419354\n",
      "Already finished: 62500 62500\n",
      "\tMine acc: 62.8208\n",
      "\tTheir acc: 85.5504\n",
      "Already finished: 63000 63000\n",
      "\tMine acc: 62.82857142857143\n",
      "\tTheir acc: 85.56666666666666\n",
      "Already finished: 63500 63500\n",
      "\tMine acc: 62.826771653543304\n",
      "\tTheir acc: 85.5748031496063\n",
      "Already finished: 64000 64000\n",
      "\tMine acc: 62.85625\n",
      "\tTheir acc: 85.5875\n",
      "Already finished: 64500 64500\n",
      "\tMine acc: 62.862015503875966\n",
      "\tTheir acc: 85.56589147286822\n",
      "Already finished: 65000 65000\n",
      "\tMine acc: 62.85846153846154\n",
      "\tTheir acc: 85.55692307692307\n",
      "Already finished: 65500 65500\n",
      "\tMine acc: 62.87480916030535\n",
      "\tTheir acc: 85.54809160305344\n",
      "Already finished: 66000 66000\n",
      "\tMine acc: 62.871212121212125\n",
      "\tTheir acc: 85.56212121212121\n",
      "Already finished: 66500 66500\n",
      "\tMine acc: 62.866165413533835\n",
      "\tTheir acc: 85.55639097744361\n",
      "Already finished: 67000 67000\n",
      "\tMine acc: 62.850746268656714\n",
      "\tTheir acc: 85.56417910447762\n",
      "Already finished: 67500 67500\n",
      "\tMine acc: 62.85333333333333\n",
      "\tTheir acc: 85.55111111111111\n",
      "Already finished: 68000 68000\n",
      "\tMine acc: 62.86764705882353\n",
      "\tTheir acc: 85.56911764705882\n",
      "Already finished: 68500 68500\n",
      "\tMine acc: 62.85109489051095\n",
      "\tTheir acc: 85.56496350364964\n",
      "Already finished: 69000 69000\n",
      "\tMine acc: 62.86666666666667\n",
      "\tTheir acc: 85.57391304347826\n",
      "Already finished: 69500 69500\n",
      "\tMine acc: 62.856115107913666\n",
      "\tTheir acc: 85.58129496402877\n",
      "Already finished: 70000 70000\n",
      "\tMine acc: 62.85857142857143\n",
      "\tTheir acc: 85.60285714285715\n",
      "Already finished: 70500 70500\n",
      "\tMine acc: 62.85957446808511\n",
      "\tTheir acc: 85.58581560283687\n",
      "Already finished: 71000 71000\n",
      "\tMine acc: 62.84788732394366\n",
      "\tTheir acc: 85.5830985915493\n",
      "Already finished: 71500 71500\n",
      "\tMine acc: 62.85034965034965\n",
      "\tTheir acc: 85.58321678321678\n",
      "Already finished: 72000 72000\n",
      "\tMine acc: 62.84722222222222\n",
      "\tTheir acc: 85.5875\n",
      "Already finished: 72500 72500\n",
      "\tMine acc: 62.83586206896552\n",
      "\tTheir acc: 85.59724137931035\n",
      "Already finished: 73000 73000\n",
      "\tMine acc: 62.847945205479455\n",
      "\tTheir acc: 85.61506849315069\n",
      "Already finished: 73500 73500\n",
      "\tMine acc: 62.82993197278912\n",
      "\tTheir acc: 85.58367346938776\n",
      "Already finished: 74000 74000\n",
      "\tMine acc: 62.82297297297297\n",
      "\tTheir acc: 85.57972972972973\n",
      "Already finished: 74500 74500\n",
      "\tMine acc: 62.83758389261745\n",
      "\tTheir acc: 85.60268456375839\n",
      "Already finished: 75000 75000\n",
      "\tMine acc: 62.812\n",
      "\tTheir acc: 85.58133333333333\n",
      "Already finished: 75500 75500\n",
      "\tMine acc: 62.81192052980133\n",
      "\tTheir acc: 85.59470198675497\n",
      "Already finished: 76000 76000\n",
      "\tMine acc: 62.825\n",
      "\tTheir acc: 85.59078947368421\n",
      "Already finished: 76500 76500\n",
      "\tMine acc: 62.840522875816994\n",
      "\tTheir acc: 85.60392156862746\n",
      "Already finished: 77000 77000\n",
      "\tMine acc: 62.84155844155844\n",
      "\tTheir acc: 85.6038961038961\n",
      "Already finished: 77500 77500\n",
      "\tMine acc: 62.861935483870965\n",
      "\tTheir acc: 85.61419354838709\n",
      "Already finished: 78000 78000\n",
      "\tMine acc: 62.8474358974359\n",
      "\tTheir acc: 85.61666666666666\n",
      "Already finished: 78500 78500\n",
      "\tMine acc: 62.86114649681529\n",
      "\tTheir acc: 85.64076433121019\n",
      "Already finished: 79000 79000\n",
      "\tMine acc: 62.868354430379746\n",
      "\tTheir acc: 85.64810126582279\n",
      "Already finished: 79500 79500\n",
      "\tMine acc: 62.86666666666667\n",
      "\tTheir acc: 85.65031446540881\n",
      "Already finished: 80000 80000\n",
      "\tMine acc: 62.8875\n",
      "\tTheir acc: 85.65\n",
      "Already finished: 80500 80500\n",
      "\tMine acc: 62.89068322981367\n",
      "\tTheir acc: 85.6472049689441\n",
      "Already finished: 81000 81000\n",
      "\tMine acc: 62.88395061728395\n",
      "\tTheir acc: 85.64691358024692\n",
      "Already finished: 81500 81500\n",
      "\tMine acc: 62.88834355828221\n",
      "\tTheir acc: 85.65766871165644\n",
      "Already finished: 82000 82000\n",
      "\tMine acc: 62.8719512195122\n",
      "\tTheir acc: 85.64634146341463\n",
      "Already finished: 82500 82500\n",
      "\tMine acc: 62.86424242424243\n",
      "\tTheir acc: 85.62545454545455\n",
      "Already finished: 83000 83000\n",
      "\tMine acc: 62.86265060240964\n",
      "\tTheir acc: 85.63373493975904\n",
      "Already finished: 83500 83500\n",
      "\tMine acc: 62.875449101796406\n",
      "\tTheir acc: 85.63233532934132\n",
      "Already finished: 84000 84000\n",
      "\tMine acc: 62.87619047619047\n",
      "\tTheir acc: 85.63690476190476\n",
      "Already finished: 84500 84500\n",
      "\tMine acc: 62.90414201183432\n",
      "\tTheir acc: 85.63076923076923\n",
      "Already finished: 85000 85000\n",
      "\tMine acc: 62.90588235294118\n",
      "\tTheir acc: 85.63411764705883\n",
      "Already finished: 85500 85500\n",
      "\tMine acc: 62.89590643274854\n",
      "\tTheir acc: 85.62923976608187\n",
      "Already finished: 86000 86000\n",
      "\tMine acc: 62.902325581395345\n",
      "\tTheir acc: 85.63720930232559\n",
      "Already finished: 86500 86500\n",
      "\tMine acc: 62.89364161849711\n",
      "\tTheir acc: 85.63815028901735\n",
      "Already finished: 87000 87000\n",
      "\tMine acc: 62.89770114942529\n",
      "\tTheir acc: 85.63793103448276\n",
      "Already finished: 87500 87500\n",
      "\tMine acc: 62.885714285714286\n",
      "\tTheir acc: 85.63542857142858\n",
      "Already finished: 88000 88000\n",
      "\tMine acc: 62.89204545454545\n",
      "\tTheir acc: 85.62613636363636\n",
      "Already finished: 88500 88500\n",
      "\tMine acc: 62.893785310734465\n",
      "\tTheir acc: 85.62146892655367\n",
      "Already finished: 89000 89000\n",
      "\tMine acc: 62.89438202247191\n",
      "\tTheir acc: 85.63483146067416\n",
      "Already finished: 89500 89500\n",
      "\tMine acc: 62.89608938547486\n",
      "\tTheir acc: 85.64022346368715\n",
      "Already finished: 90000 90000\n",
      "\tMine acc: 62.888888888888886\n",
      "\tTheir acc: 85.63666666666667\n",
      "Already finished: 90500 90500\n",
      "\tMine acc: 62.90276243093923\n",
      "\tTheir acc: 85.646408839779\n",
      "Already finished: 91000 91000\n",
      "\tMine acc: 62.88901098901099\n",
      "\tTheir acc: 85.64065934065934\n",
      "Already finished: 91500 91500\n",
      "\tMine acc: 62.895081967213116\n",
      "\tTheir acc: 85.64262295081967\n",
      "Already finished: 92000 92000\n",
      "\tMine acc: 62.892391304347825\n",
      "\tTheir acc: 85.6413043478261\n",
      "Already finished: 92500 92500\n",
      "\tMine acc: 62.88\n",
      "\tTheir acc: 85.6454054054054\n",
      "Already finished: 93000 93000\n",
      "\tMine acc: 62.88494623655914\n",
      "\tTheir acc: 85.64408602150537\n",
      "Already finished: 93500 93500\n",
      "\tMine acc: 62.89625668449198\n",
      "\tTheir acc: 85.64491978609625\n",
      "Already finished: 94000 94000\n",
      "\tMine acc: 62.91489361702128\n",
      "\tTheir acc: 85.64468085106382\n",
      "Already finished: 94500 94500\n",
      "\tMine acc: 62.91851851851852\n",
      "\tTheir acc: 85.65396825396826\n",
      "Already finished: 95000 95000\n",
      "\tMine acc: 62.92\n",
      "\tTheir acc: 85.63368421052631\n",
      "Already finished: 95500 95500\n",
      "\tMine acc: 62.904712041884814\n",
      "\tTheir acc: 85.63141361256544\n",
      "Already finished: 96000 96000\n",
      "\tMine acc: 62.91354166666667\n",
      "\tTheir acc: 85.6375\n",
      "Already finished: 96500 96500\n",
      "\tMine acc: 62.895336787564766\n",
      "\tTheir acc: 85.61450777202073\n",
      "Already finished: 97000 97000\n",
      "\tMine acc: 62.896907216494846\n",
      "\tTheir acc: 85.60618556701031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 97500 97500\n",
      "\tMine acc: 62.91897435897436\n",
      "\tTheir acc: 85.60205128205128\n",
      "Already finished: 98000 98000\n",
      "\tMine acc: 62.92857142857143\n",
      "\tTheir acc: 85.60306122448979\n",
      "Already finished: 98500 98500\n",
      "\tMine acc: 62.93502538071066\n",
      "\tTheir acc: 85.60812182741117\n",
      "Already finished: 99000 99000\n",
      "\tMine acc: 62.93131313131313\n",
      "\tTheir acc: 85.60808080808081\n",
      "Already finished: 99500 99500\n",
      "\tMine acc: 62.94070351758794\n",
      "\tTheir acc: 85.62110552763819\n",
      "Already finished: 100000 100000\n",
      "\tMine acc: 62.949\n",
      "\tTheir acc: 85.619\n",
      "Already finished: 100500 100500\n",
      "\tMine acc: 62.94726368159204\n",
      "\tTheir acc: 85.62388059701493\n",
      "Already finished: 101000 101000\n",
      "\tMine acc: 62.95247524752475\n",
      "\tTheir acc: 85.63168316831683\n",
      "Already finished: 101500 101500\n",
      "\tMine acc: 62.95566502463054\n",
      "\tTheir acc: 85.63448275862069\n",
      "Already finished: 102000 102000\n",
      "\tMine acc: 62.95392156862745\n",
      "\tTheir acc: 85.63627450980393\n",
      "Already finished: 102500 102500\n",
      "\tMine acc: 62.93853658536585\n",
      "\tTheir acc: 85.61853658536586\n",
      "Already finished: 103000 103000\n",
      "\tMine acc: 62.925242718446604\n",
      "\tTheir acc: 85.60679611650485\n",
      "Already finished: 103500 103500\n",
      "\tMine acc: 62.91497584541063\n",
      "\tTheir acc: 85.6\n",
      "Already finished: 104000 104000\n",
      "\tMine acc: 62.916346153846156\n",
      "\tTheir acc: 85.60576923076923\n",
      "Already finished: 104500 104500\n",
      "\tMine acc: 62.911004784689\n",
      "\tTheir acc: 85.60574162679426\n",
      "Already finished: 105000 105000\n",
      "\tMine acc: 62.90761904761905\n",
      "\tTheir acc: 85.6047619047619\n",
      "Already finished: 105500 105500\n",
      "\tMine acc: 62.91279620853081\n",
      "\tTheir acc: 85.6218009478673\n"
     ]
    }
   ],
   "source": [
    "upper_their=0.0\n",
    "upper_mine=0.0\n",
    "vis=0\n",
    "total={}\n",
    "random.shuffle(val_all)\n",
    "invalid=[]\n",
    "for row in val_all:\n",
    "    if row['ans_type']!='other':\n",
    "        continue\n",
    "    if row['idx'] not in qid_to_t5:\n",
    "            continue\n",
    "    vis+=1\n",
    "    #if vis>30:\n",
    "    #    break\n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \n",
    "    base_info=qid_to_t5[row['idx']]\n",
    "    statement=base_info['prompts'][0]\n",
    "    try:\n",
    "        t5_pred=candidate_generator(statement)\n",
    "    except:\n",
    "        invalid.append(row['idx'])\n",
    "        print ('Invalid!!!!',row['idx'])\n",
    "        continue\n",
    "        \n",
    "    if len(base_info['labels'])<80:\n",
    "        t5_pred=base_info['labels']\n",
    "    \n",
    "    if verify_ans(row['answer'],t5_pred)[0]:\n",
    "        upper_mine+=1\n",
    "    if verify_ans(row['answer'],base_info['labels'])[0]:\n",
    "        upper_their+=1\n",
    "    \n",
    "    if vis%500==0:\n",
    "        print ('Already finished:',vis,len(total)+1)\n",
    "        print ('\\tMine acc:',100.0*upper_mine/vis)\n",
    "        print ('\\tTheir acc:',100.0*upper_their/vis)\n",
    "    total[row['idx']]=t5_pred\n",
    "    #json.dump(t5_pred,\n",
    "    #          open(os.path.join('mine_t5_file',row['idx']+'.json'),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c42a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('mine_t5_file/open_ended.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4b3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc1802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_types=[\n",
    "    'what are the','what is','what is the man','what does the',\n",
    "    ###'why','why is the','how',\n",
    "    ##'which','what kind of','what is the','what type of','what',\n",
    "    ##'who is','what is this','what sport is','what room is','what animal is',\n",
    "    'which','what kind of','what is the','what type of','what',\n",
    "    'who is','what is this','what sport is','what room is','what animal is',\n",
    "    \n",
    "    'where is the','what is on the',\n",
    "    'what time','what is in the','what are',\n",
    "    'what is the person','where are the',\n",
    "    #'what brand',\n",
    "    'what is the woman',\n",
    "    'what is the name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07755c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_types=['what is the woman','what is on the']\n",
    "for q_t in q_types:\n",
    "    vis=0\n",
    "    upper=0.0\n",
    "    bart_results=load_pkl(os.path.join('bart_vqa',q_t+'.pkl'))\n",
    "    statement_results=load_pkl(os.path.join('../qanli',q_t+'.pkl'))\n",
    "    random.shuffle(val_based_qt[q_t])\n",
    "    upper_acc=0.0\n",
    "    print(q_t,len(val_based_qt[q_t]))\n",
    "    save_pred={}\n",
    "    for row in val_based_qt[q_t]:\n",
    "        vis+=1\n",
    "        answers=row['answer']\n",
    "        ques=row['question']\n",
    "    \n",
    "        statement=generate_statement(statement_results[row['idx']],\n",
    "                                     row['question'])\n",
    "        try:\n",
    "            t5_pred=candidate_generator(statement)\n",
    "        except:\n",
    "            t5_pred=bart_results[row['idx']]\n",
    "        #t5_pred=candidate_generator(statement)\n",
    "            \n",
    "        save_pred[row['idx']]=t5_pred\n",
    "        upper,in_list=verify_ans(row['answer'],t5_pred)\n",
    "        if upper:\n",
    "            upper_acc+=1\n",
    "        if vis%200==0:\n",
    "            print ('Upper acc',upper_acc*100.0/vis)\n",
    "    print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "    pkl.dump(save_pred,open(os.path.join('t5_vqa',q_t+'.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31b8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c940ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12578\n"
     ]
    }
   ],
   "source": [
    "val_all=json.load(\n",
    "    open(os.path.join(GQA_PATH,'original','testdev_balanced_questions.json')\n",
    "         ,'r')\n",
    ")\n",
    "print (len(val_all))\n",
    "names=list(val_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e627556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of testing data: 132062\n",
      "dict_keys(['question', 'answer', 'img', 'layout', 'key', 'width', 'height', 'full_ans', 'types']) \n",
      " {'question': 'What is this bird called?', 'answer': 'parrot', 'img': '2405722', 'layout': [{'operation': 'select', 'dependencies': [], 'argument': 'bird (329774)'}, {'operation': 'query', 'dependencies': [0], 'argument': 'name'}], 'key': '05515938', 'width': 500, 'height': 375, 'full_ans': 'This is a parrot.', 'types': {'detailed': 'categoryThis', 'semantic': 'cat', 'structural': 'query'}}\n"
     ]
    }
   ],
   "source": [
    "val_all=load_json(os.path.join(GQA_PATH,'questions','val_all_data.json'))\n",
    "print ('Length of testing data:',len(val_all))\n",
    "print (val_all[0].keys(),'\\n',val_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266ca666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'verify': 2252, 'query': 6805, 'logical': 1803, 'choose': 1129, 'compare': 589})\n"
     ]
    }
   ],
   "source": [
    "q_types_dict=defaultdict(int)\n",
    "for name in val_all:\n",
    "    row=val_all[name]\n",
    "    q_types_dict[row['types']['structural']]+=1\n",
    "print (q_types_dict)\n",
    "val_based_qt={q_t:[] for q_t in q_types_dict}\n",
    "for name in val_all:\n",
    "    row=val_all[name]\n",
    "    row['key']=name\n",
    "    val_based_qt[row['types']['structural']].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982fc348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f410d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'query': 68167, 'choose': 16229, 'verify': 27413, 'compare': 4157, 'logical': 16096})\n"
     ]
    }
   ],
   "source": [
    "q_types_dict=defaultdict(int)\n",
    "for row in val_all:\n",
    "    q_types_dict[row['types']['structural']]+=1\n",
    "print (q_types_dict)\n",
    "val_based_qt={q_t:[] for q_t in q_types_dict}\n",
    "for row in val_all:\n",
    "    val_based_qt[row['types']['structural']].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc6f7990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68167\n"
     ]
    }
   ],
   "source": [
    "temp_file=load_pkl('../GQA_ques_convertor/query_updates.pkl')\n",
    "print(len(temp_file))\n",
    "names=list(temp_file.keys())\n",
    "print (temp_file[names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8addb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93751b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6805\n",
      "Item is wearing the dress.\n"
     ]
    }
   ],
   "source": [
    "temp_file=load_pkl('../GQA_ques_convertor/dev_query.pkl')\n",
    "print(len(temp_file))\n",
    "names=list(temp_file.keys())\n",
    "print (temp_file[names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00be8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47a141f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "invalid=0\n",
    "random.shuffle(val_based_qt['query'])\n",
    "for row in val_based_qt['query']:\n",
    "    vis+=1\n",
    "    if type(temp_file[row['key']]) is not str:\n",
    "        temp_file[row['key']]=row['full_ans'].lower().replace(row['answer'],'item')\n",
    "        if invalid<20:\n",
    "            print (row['question'])\n",
    "            print ('\\t',temp_file[row['key']])\n",
    "        invalid+=1\n",
    "print (invalid)\n",
    "    #print (row['question'])\n",
    "    #print ('\\t',temp_file[row['key']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e6c7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(temp_file,open('../GQA_ques_convertor/query_updates.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189f404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f3ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e727f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which shape is the soccer ball that is above the tree?\n",
      "\t The soccer ball that is above the tree is item.\n",
      "What are the flowers in front of?\n",
      "\t The flowers in front of are item.\n",
      "What item of furniture is sitting atop the floor?\n",
      "\t Item is sitting atop the floor.\n",
      "What color is the picture?\n",
      "\t The picture is item.\n",
      "Who is sitting?\n",
      "\t Item is sitting.\n",
      "What is the bison doing?\n",
      "\t The bison is doing item.\n",
      "What's attached to the coat?\n",
      "\t Item's attached to the coat.\n",
      "What is leaning against the window?\n",
      "\t Item is leaning against the window.\n",
      "What animal is the male person carrying?\n",
      "\t The male person is carrying item.\n",
      "What's the belt holding onto?\n",
      "\t The belt's holding onto item.\n",
      "What is the vehicle that the fence is in front of called?\n",
      "\t The vehicle that the fence is in front of called is item.\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "random.shuffle(val_based_qt['query'])\n",
    "for row in val_based_qt['query']:\n",
    "    if vis>10:\n",
    "        break\n",
    "    vis+=1\n",
    "    print (row['question'])\n",
    "    print ('\\t',temp_file[row['key']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f2539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e381ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE=1\n",
    "torch.cuda.set_device(CUDA_DEVICE)\n",
    "device = torch.device(\"cuda:\"+str(CUDA_DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d48dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model=bart_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe778d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2848bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statement(sent):\n",
    "    flag=True\n",
    "    words=[]\n",
    "    for w in sent[:-1].lower().split(' '):\n",
    "        if w =='item' and flag:\n",
    "            flag=False\n",
    "            words.append('<extra_id_0>')\n",
    "        else:\n",
    "            words.append(w)\n",
    "    words.append('.')\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ae09314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6805\n",
      "Which kind of animal isn't short? goat n187961\n",
      "\t n't short is <extra_id_0> .\n",
      "\tMine:  211 False []\n",
      "['hi', 'big', 'impossible', 'missing', 'poor', 'valid', 'like', 'accurate', 'said', 'new', 'another', 'well', 'free', 'cool', 'less', 'already', 'getting', 'ha', 'great', 'first', 'full', 'known', 'anyone', 'possible', 'limited', 'necessary', 'total', 'fast', 'meaning', 'correct', 'wonderful', 'middle', 'best', 'need', 'beautiful', 'available', 'stupid', 'word', 'fat', 'co', 'thin', 'used', 'usually', 'many', 'longer', 'coming', 'shorter', 'top', 'difficult', 'meant', 'anyway', 'lost', 'nice', 'even', 'mid', 'completely', 'dead', 'life', 'nu', 'complete', 'miss', 'done', 'words', 'whole', 'fair', 'la', 'fine', 'bad', 'ca', 'man', 'yet', 'tough', 'go', 'boring', 'enough', 'always', 'safe', 'bit', 'also', 'interesting', 'must', 'going', 'fun', 'short', 'rather', 'non', 'last', 'us', 'truth', 'important', 'back', 'without', 'tall', 'cute', 'really', 'low', 'fake', 'high', 'red', 'made', 'smart', 'actually', 'time', 'nothing', 'good', 'got', 'strong', 'excellent', 'useless', 'hard', 'much', 'slow', 'love', 'normal', 'right', 'mean', 'number', 'super', 'end', 'half', 'amazing', 'sure', 'wrong', 'clear', 'required', 'two', 'next', 'gone', 'one', 'either', 'usual', 'expensive', 'small', 'never', 'every', 'ever', 'still', 'healthy', 'cut', 'way', 'equal', 'totally', 'quite', 'okay', 'wide', 'useful', 'worth', 'extremely', 'saying', 'honest', 'round', 'due', 'funny', 'nearly', 'around', 'real', 'single', 'sweet', 'sometimes', 'read', 'pretty', 'ugly', 'written', 'en', 'fact', 'almost', 'kind', 'needed', 'get', 'perfect', 'hot', 'given', 'easy', 'surely', 'con', 'extra', 'anything', 'false', 'left', 'called', 'little', 'probably', 'simple', 'common', 'ok', 'something', 'er', 'exactly', 'simply', 'brief', 'often', 'better', 'quality', 'certainly', 'seen', 'quick', 'acceptable', 'definitely', 'everything', 'different', 'length', 'not', 'long', 'found', 'near', 'black', 'true', 'cheap', 'proper', 'indeed', 'far'] \n",
      "\n",
      "Which place is it? city n217003\n",
      "\t it is <extra_id_0> .\n",
      "\tMine:  252 False []\n",
      "['big', 'impossible', 'missing', 'valid', 'like', 'working', 'present', 'complicated', 'accurate', 'said', 'new', 'considered', 'another', 'well', 'compatible', 'click', 'updated', 'installed', 'free', 'cool', 'less', 'already', 'getting', 'the', 'alive', 'great', 'first', 'full', 'looking', 'known', 'possible', 'limited', 'necessary', 'valuable', 'fascinating', 'absolutely', 'fast', 'correct', 'moving', 'wonderful', 'connected', 'packed', 'best', 'available', 'beautiful', 'close', 'used', 'usually', 'convenient', 'many', 'especially', 'coming', 'difficult', 'powerful', 'awesome', 'truly', 'meant', 'anyway', 'essential', 'nice', 'open', 'independent', 'even', 'fabulous', 'completely', 'presented', 'impressive', 'dead', 'displayed', 'life', 'provided', 'taken', 'named', 'dark', 'fantastic', 'complete', 'currently', 'done', 'online', 'obvious', 'outstanding', 'fine', 'bad', 'yet', 'ideal', 'using', 'tough', 'stunning', 'exciting', 'enough', 'always', 'ready', 'part', 'obviously', 'highly', 'finally', 'web', 'safe', 'superb', 'also', 'interesting', 'associated', 'going', 'fun', 'short', 'rather', 'us', 'published', 'making', 'rich', 'important', 'back', 'without', 'offered', 'designed', 'capable', 'happening', 'held', 'really', 'high', 'likely', 'located', 'made', 'actually', 'time', 'cost', 'particularly', 'nothing', 'good', 'released', 'strong', 'excellent', 'work', 'within', 'useless', 'hard', 'much', 'entirely', 'beyond', 'shown', 'right', 'normal', 'worthwhile', 'super', 'official', 'today', 'amazing', 'relevant', 'perfectly', 'sure', 'applicable', 'huge', 'challenging', 'wrong', 'clear', 'required', 'recommended', 'powered', 'created', 'rain', 'similar', 'gone', 'one', 'magnificent', 'expensive', 'running', 'never', 'every', 'small', 'ever', 'becoming', 'still', 'effective', 'healthy', 'delivered', 'linked', 'protected', 'way', 'related', 'price', 'totally', 'quite', 'okay', 'built', 'useful', 'worth', 'extremely', 'saying', 'unique', 'due', 'successful', 'funny', 'real', 'fully', 'around', 'brilliant', 'clearly', 'read', 'mentioned', 'pretty', 'written', 'lovely', 'almost', 'kind', 'needed', 'helpful', 'beautifully', 'properly', 'perfect', 'hot', 'easier', 'given', 'posted', 'easy', 'special', 'surely', 'home', 'appropriate', 'called', 'probably', 'simple', 'something', 'suitable', 'simply', 'supposed', 'easily', 'better', 'gorgeous', 'fairly', 'certainly', 'exactly', 'seen', 'accessible', 'often', 'explained', 'listed', 'set', 'remarkable', 'produced', 'definitely', 'original', 'everything', 'different', 'not', 'long', 'found', 'black', 'fresh', 'true', 'everywhere', 'indeed', 'far'] \n",
      "\n",
      "What is the color of the colorful flowers? green n49310\n",
      "\t the color of the colorful flowers is <extra_id_0> .\n",
      "\tMine:  279 True ['green']\n",
      "['big', 'selected', 'key', 'unforgettable', 'like', 'present', 'diverse', 'said', 'delicate', 'new', 'considered', 'another', 'well', 'delicious', 'striking', 'large', 'exceptional', 'shocking', 'cool', 'mu', 'inspiring', 'free', 'less', 'already', 'deep', 'described', 'the', 'alive', 'great', 'unusual', 'elegant', 'full', 'looking', 'incredible', 'complementary', 'known', 'possible', 'limited', 'complex', 'fascinating', 'eye', 'absolutely', 'featured', 'wonderful', 'brought', 'lively', 'golden', 'packed', 'best', 'available', 'beautiful', 'fade', 'co', 'used', 'usually', 'many', 'spring', 'coordinated', 'especially', 'coming', 'changing', 'wild', 'difficult', 'powerful', 'awesome', 'truly', 'extraordinary', 'naturally', 'carefully', 'essential', 'nice', 'equally', 'distinctive', 'even', 'matching', 'fabulous', 'completely', 'impressive', 'artificial', 'yellow', 'constantly', 'chosen', 'soothing', 'cheerful', 'displayed', 'provided', 'fantastic', 'dark', 'taken', 'deeply', 'complete', 'gold', 'adorable', 'done', 'abundant', 'intense', 'outstanding', 'happy', 'colored', 'fine', 'ideal', 'using', 'stunning', 'exciting', 'enough', 'bold', 'always', 'part', 'white', 'refreshing', 'highly', 'various', 'widely', 'superb', 'also', 'mostly', 'interesting', 'mixed', 'going', 'exceptionally', 'fun', 'famous', 'rather', 'rainbow', 'filled', 'varied', 'visible', 'specially', 'making', 'soft', 'rich', 'important', 'shining', 'glowing', 'natural', 'green', 'attractive', 'designed', 'offered', 'cute', 'really', 'change', 'high', 'red', 'made', 'painted', 'magical', 'actually', 'particularly', 'purple', 'exquisite', 'good', 'strong', 'excellent', 'brown', 'stylish', 'hard', 'much', 'neutral', 'blue', 'subtle', 'beyond', 'shown', 'right', 'summer', 'wonderfully', 'super', 'water', 'amazing', 'perfectly', 'sure', 'huge', 'violet', 'match', 'clear', 'printed', 'created', 'similar', 'tea', 'one', 'warm', 'flower', 'endless', 'harmonious', 'small', 'magnificent', 'every', 'splendid', 'popular', 'still', 'enhanced', 'breathtaking', 'light', 'rose', 'among', 'related', 'way', 'totally', 'quite', 'captivating', 'marvelous', 'wide', 'worth', 'changed', 'extremely', 'unique', 'orange', 'pale', 'color', 'pure', 'real', 'highlighted', 'fully', 'charming', 'sweet', 'spectacular', 'brilliant', 'clearly', 'added', 'pretty', 'lovely', 'astonishing', 'almost', 'vivid', 'inviting', 'beautifully', 'vibrant', 'perfect', 'delightful', 'hot', 'given', 'variety', 'rare', 'easy', 'pastel', 'special', 'surely', 'sold', 'appropriate', 'glorious', 'extra', 'pink', 'called', 'appealing', 'simple', 'something', 'radiant', 'suitable', 'simply', 'exactly', 'easily', 'bloom', 'colorful', 'gorgeous', 'certainly', 'multi', 'seen', 'better', 'according', 'often', 'set', 'remarkable', 'slightly', 'inspired', 'definitely', 'original', 'everything', 'different', 'bright', 'picked', 'included', 'long', 'shades', 'black', 'fresh', 'true', 'everywhere', 'indeed', 'far'] \n",
      "\n",
      "What color is the traffic light that the street sign is hanging from? black n532213\n",
      "\t the traffic light that the street sign is hanging from is <extra_id_0> .\n",
      "\tMine:  208 True ['black']\n",
      "['on', 'stopped', 'facing', 'key', 'hanging', 'missing', 'type', 'label', 'like', 'working', 'underneath', 'sign', 'said', 'new', 'another', 'well', 'installed', 'operated', 'already', 'getting', 'approximately', 'the', 'full', 'looking', 'known', 'american', 'correct', 'moving', 'connected', 'says', 'holding', 'available', 'headed', 'shot', 'fixed', 'standing', 'used', 'turning', 'stuck', 'no', 'usually', 'say', 'broken', 'coming', 'changing', 'driving', 'marked', 'open', 'yellow', 'operating', 'spot', 'dead', 'displayed', 'dark', 'named', 'three', 'mark', 'point', 'currently', 'empty', 'south', 'replaced', 'colored', 'post', 'using', 'situated', 'always', 'switched', 'part', 'white', 'obviously', 'somewhere', 'covered', 'second', 'also', 'associated', 'going', 'normally', 'visible', 'us', 'williams', 'turned', 'making', 'le', 'nearby', 'back', 'blocked', 'green', 'designed', 'signed', 'inside', 'really', 'low', 'lit', 'red', 'located', 'made', 'painted', 'led', 'following', 'time', 'actually', 'purple', 'john', 'good', 'brown', 'unknown', 'much', 'blue', 'shown', 'right', 'closed', 'asking', 'number', 'disabled', 'identified', 'super', 'behind', 'wrong', 'identical', 'illuminate', 'powered', 'two', 'next', 'similar', 'city', 'gone', 'one', 'either', 'blink', 'running', 'attached', 'still', 'road', 'lighting', 'light', 'dim', 'reading', 'way', 'quite', 'built', 'worth', 'changed', 'saying', 'orange', 'placed', 'assigned', 'real', 'showing', 'around', 'highlighted', 'single', 'indicated', 'read', 'traffic', 'clearly', 'outside', 'pretty', 'crossed', 'at', 'written', 'st', 'apparently', 'tied', 'street', 'gray', 'given', 'posted', 'stop', 'silver', 'designated', 'in', 'electric', 'symbol', 'called', 'blank', 'left', 'north', 'code', 'flash', 'probably', 'question', 'something', 'activate', 'simply', 'supposed', 'exactly', 'picture', 'seen', 'lights', 'listed', 'set', 'west', 'slightly', 'definitely', 'sitting', 'different', 'bright', 'wire', 'included', 'not', 'signal', 'near', 'black', 'high', 'heading', 'indeed', 'far'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What animals are shown in the photo? elephants n543966\n",
      "\t <extra_id_0> are shown in the photo .\n",
      "\tMine:  251 False []\n",
      "['tips', 'sizes', 'key', 'differences', 'configuration', 'pictures', 'type', 'connections', 'like', 'working', 'plates', 'look', 'several', 'specs', 'diagram', 'windows', 'cups', 'needs', 'new', 'exact', 'well', 'aspects', 'pieces', 'glass', 'connection', 'product', 'designs', 'colors', 'numbers', 'first', 'full', 'others', 'finished', 'arrangements', 'unit', 'rules', 'material', 'order', 'frames', 'information', 'control', 'steps', 'best', 'available', 'beautiful', 'parameters', 'structure', 'test', 'version', 'letters', 'size', 'used', 'many', 'elements', 'spring', 'lamp', 'top', 'conditions', 'drawings', 'tray', 'versions', 'specific', 'combination', 'tools', 'slides', 'fit', 'button', 'dimensions', 'space', 'provided', 'area', 'three', 'photo', 'problems', 'styles', 'logo', 'words', 'attachment', 'dimension', 'fitting', 'details', 'image', 'requirements', 'holes', 'tiles', 'photographs', 'points', 'part', 'white', 'application', 'various', 'cup', 'example', 'also', 'etc', 'standard', 'package', 'data', 'images', 'features', 'form', 'appearance', 'result', 'glasses', 'links', 'products', 'inside', 'back', 'without', 'feature', 'surface', 'wheel', 'things', 'hand', 'case', 'characteristics', 'materials', 'made', 'following', 'time', 'model', 'photos', 'cables', 'function', 'work', 'assembly', 'four', 'construction', 'prices', 'blue', 'box', 'system', 'shown', 'areas', 'teeth', 'measures', 'types', 'number', 'controls', 'measurements', 'edges', 'end', 'parts', 'pages', 'plastic', 'metal', 'variations', 'doors', 'five', 'lines', 'frame', 'show', 'detail', 'two', 'patterns', 'per', 'together', 'instructions', 'power', 'inner', 'display', 'similar', 'day', 'side', 'components', 'works', 'one', 'layout', 'shoes', 'small', 'design', 'wood', 'shape', 'ingredients', 'body', 'wheels', 'items', 'possibilities', 'specifications', 'attached', 'still', 'changes', 'light', 'properties', 'decorations', 'way', 'price', 'window', 'models', 'buttons', 'connector', 'feet', 'style', 'built', 'detailed', 'directions', 'functions', 'accessories', 'color', 'values', 'legs', 'panels', 'outside', 'sides', 'height', 'pattern', 'screws', 'keys', 'services', 'examples', 'front', 'samples', 'opening', 'main', 'individual', 'special', 'table', 'extra', 'left', 'effects', 'shapes', 'results', 'machine', 'arrangement', 'boxes', 'contents', 'ones', 'according', 'quality', 'picture', 'lights', 'flowers', 'set', 'cable', 'video', 'original', 'different', 'wire', 'car', 'interior', 'included', 'length', 'door', 'slide', 'shades', 'installation', 'additional', 'black', 'rings', 'options', 'settings'] \n",
      "\n",
      "Which color are the balls that are in the bottom of the image? white n146522\n",
      "\t the balls that are in the bottom of the image are <extra_id_0> .\n",
      "\tMine:  251 True ['white']\n",
      "['big', 'mine', 'soccer', 'missing', 'pictures', 'double', 'optional', 'like', 'working', 'separated', 'rubber', 'said', 'new', 'considered', 'another', 'large', 'pieces', 'free', 'less', 'falling', 'already', 'getting', 'magic', 'easter', 'approximately', 'colors', 'the', 'numbers', 'actual', 'full', 'looking', 'known', 'hollow', 'possible', 'represented', 'american', 'tiny', 'moving', 'toys', 'connected', 'correct', 'golden', 'holding', 'best', 'available', 'classified', 'baby', 'bubble', 'letters', 'size', 'used', 'hidden', 'usually', 'spring', 'broken', 'coming', 'meant', 'ball', 'marked', 'giant', 'divided', 'completely', 'yellow', 'artificial', 'floating', 'dead', 'provided', 'cotton', 'named', 'taken', 'football', 'three', 'gold', 'crystal', 'flying', 'diamond', 'bigger', 'done', 'empty', 'words', 'solid', 'played', 'replaced', 'colored', 'bad', 'regular', 'using', 'stickers', 'beads', 'go', 'objects', 'always', 'part', 'white', 'obviously', 'covered', 'balls', 'formed', 'also', 'mostly', 'associated', 'sent', 'going', 'normally', 'images', 'men', 'non', 'filled', 'golf', 'links', 'making', 'soft', 'inside', 'important', 'back', 'birds', 'natural', 'green', 'designed', 'disc', 'things', 'snow', 'held', 'fake', 'really', 'loaded', 'likely', 'red', 'located', 'made', 'separate', 'painted', 'actually', 'hockey', 'purple', 'fish', 'good', 'basketball', 'selling', 'brown', 'worn', 'useless', 'air', 'smaller', 'kids', 'hard', 'caused', 'marble', 'four', 'women', 'names', 'blue', 'chinese', 'shown', 'right', 'closed', 'representing', 'normal', 'rolling', 'old', 'removed', 'super', 'parts', 'water', 'half', 'frozen', 'metal', 'plastic', 'huge', 'identical', 'clear', 'required', 'two', 'created', 'similar', 'gone', 'one', 'either', 'human', 'shoes', 'small', 'running', 'larger', 'wearing', 'still', 'linked', 'related', 'way', 'children', 'equal', 'quite', 'buttons', 'worth', 'saying', 'orange', 'placed', 'round', 'color', 'due', 'real', 'showing', 'around', 'bullet', 'babies', 'added', 'pretty', 'tennis', 'mini', 'playing', 'almost', 'girls', 'needed', 'eggs', 'gray', 'perfect', 'given', 'baseball', 'special', 'silver', 'sold', 'con', 'intended', 'extra', 'called', 'left', 'pink', 'little', 'probably', 'weight', 'something', 'people', 'simply', 'supposed', 'ones', 'exactly', 'often', 'stars', 'seen', 'listed', 'set', 'slightly', 'coins', 'definitely', 'invisible', 'different', 'included', 'not', 'found', 'black', 'true', 'high'] \n",
      "\n",
      "What is the man eating? sandwich n166008\n",
      "\t the man is eating <extra_id_0> .\n",
      "\tMine:  228 True ['sandwich']\n",
      "['salmon', 'big', 'eating', 'hamburger', 'it', 'like', 'several', 'yummy', 'honey', 'sandwiches', 'toast', 'grass', 'said', 'cake', 'new', 'another', 'well', 'delicious', 'foods', 'less', 'fruit', 'heavy', 'already', 'deep', 'dinner', 'milk', 'the', 'great', 'coffee', 'garbage', 'salad', 'first', 'full', 'money', 'rice', 'chocolate', 'stuff', 'nuts', 'leaves', 'nicely', 'fast', 'pasta', 'banana', 'cereal', 'desert', 'carrot', 'veggies', 'baby', 'fat', 'popcorn', 'restaurant', 'onions', 'biscuit', 'broccoli', 'snacks', 'many', 'peanut', 'juice', 'dishes', 'food', 'anyway', 'cooked', 'cricket', 'nice', 'even', 'beef', 'candy', 'dead', 'pork', 'life', 'spicy', 'lots', 'three', 'oyster', 'cookies', 'corn', 'pizza', 'whole', 'cold', 'la', 'fine', 'man', 'cakes', 'shrimp', 'go', 'away', 'lobster', 'ready', 'part', 'white', 'somewhere', 'bread', 'fruits', 'fries', 'also', 'etc', 'steak', 'normally', 'pancake', 'last', 'dog', 'daily', 'us', 'soft', 'seafood', 'inside', 'back', 'without', 'pudding', 'green', 'soup', 'beer', 'sugar', 'things', 'hand', 'really', 'lettuce', 'freshly', 'red', 'bacon', 'garlic', 'potato', 'time', 'dessert', 'fish', 'snack', 'nothing', 'apple', 'work', 'within', 'hard', 'spaghetti', 'mango', 'along', 'much', 'chicken', 'chinese', 'tomatoes', 'normal', 'right', 'walnut', 'live', 'today', 'water', 'half', 'sauce', 'behind', 'cu', 'noodles', 'wrong', 'chips', 'curry', 'two', 'next', 'together', 'tea', 'one', 'potatoes', 'lamb', 'human', 'meal', 'small', 'every', 'tonight', 'wheat', 'still', 'healthy', 'light', 'among', 'batter', 'dough', 'meat', 'quite', 'sushi', 'tomato', 'beans', 'real', 'around', 'sweet', 'outside', 'finger', 'cheese', 'spinach', 'french', 'eggs', 'sandwich', 'street', 'hot', 'butter', 'vegetable', 'special', 'star', 'home', 'ginger', 'table', 'slowly', 'anything', 'grape', 'pie', 'directly', 'yogurt', 'indian', 'meals', 'something', 'crab', 'egg', 'exactly', 'turkey', 'according', 'better', 'lunch', 'bowl', 'dish', 'vegetarian', 'breakfast', 'wine', 'different', 'everything', 'raw', 'vegetables', 'whatever', 'lemon', 'near', 'black', 'fresh', 'alone', 'good', 'sausage'] \n",
      "\n",
      "What is the piece of furniture that the luggage that is brown and black is sitting in front of? table n507959\n",
      "\t the piece of furniture that the luggage that is brown and black is sitting in front of is <extra_id_0> .\n",
      "\tMine:  249 True ['table']\n",
      "['facing', 'big', 'hanging', 'missing', 'taking', 'label', 'like', 'working', 'talking', 'underneath', 'furniture', 'said', 'new', 'bed', 'considered', 'another', 'well', 'put', 'large', 'glass', 'pieces', 'heavy', 'getting', 'already', 'described', 'approximately', 'the', 'great', 'coffee', 'dining', 'beside', 'full', 'looking', 'known', 'absolutely', 'aluminum', 'moving', 'brought', 'holding', 'best', 'available', 'beautiful', 'headed', 'classified', 'standing', 'used', 'turning', 'usually', 'broken', 'coming', 'changing', 'meant', 'marked', 'nice', 'even', 'completely', 'yellow', 'square', 'displayed', 'provided', 'dark', 'named', 'taken', 'decorated', 'three', 'straight', 'gold', 'currently', 'somewhat', 'solid', 'done', 'iron', 'empty', 'call', 'sofa', 'colored', 'fine', 'using', 'situated', 'kept', 'always', 'wooden', 'carrying', 'part', 'white', 'obviously', 'kitchen', 'piece', 'somewhere', 'covered', 'folded', 'folding', 'moved', 'safe', 'also', 'mostly', 'interesting', 'going', 'rather', 'chair', 'filled', 'making', 'turned', 'inside', 'important', 'back', 'tall', 'green', 'designed', 'house', 'desk', 'happening', 'held', 'really', 'high', 'red', 'located', 'made', 'painted', 'actually', 'purple', 'nothing', 'good', 'brand', 'maybe', 'got', 'selling', 'within', 'brown', 'four', 'along', 'much', 'oak', 'leather', 'unknown', 'marble', 'blue', 'shown', 'right', 'closed', 'asking', 'old', 'walnut', 'today', 'amazing', 'perfectly', 'sure', 'metal', 'basically', 'behind', 'plastic', 'huge', 'identical', 'clear', 'two', 'next', 'created', 'writing', 'similar', 'owned', 'gone', 'one', 'either', 'small', 'wood', 'larger', 'becoming', 'wearing', 'lying', 'attached', 'calling', 'still', 'chrome', 'light', 'related', 'reading', 'way', 'room', 'name', 'living', 'totally', 'quite', 'built', 'worth', 'extremely', 'saying', 'unique', 'placed', 'orange', 'round', 'showing', 'around', 'clearly', 'read', 'mentioned', 'outside', 'pretty', 'antique', 'playing', 'written', 'almost', 'kind', 'needed', 'front', 'gray', 'perfect', 'given', 'easy', 'rectangular', 'looked', 'silver', 'home', 'table', 'sold', 'called', 'anything', 'pink', 'left', 'probably', 'simple', 'something', 'simply', 'exactly', 'supposed', 'easily', 'often', 'couch', 'certainly', 'constructed', 'seen', 'listed', 'set', 'slightly', 'chairs', 'definitely', 'sitting', 'everything', 'different', 'included', 'long', 'found', 'near', 'black', 'waiting', 'cheap', 'wrapped', 'heading', 'indeed', 'far'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the appliance that is to the right of the tap called? refrigerator n64959\n",
      "\t the appliance that is to the right of the tap called is <extra_id_0> .\n",
      "\tMine:  209 False []\n",
      "['dishwasher', 'commonly', 'selected', 'drain', 'double', 'pressure', 'type', 'label', 'like', 'automatic', 'working', 'heater', 'boiling', 'remote', 'said', 'thermostat', 'considered', 'another', 'well', 'put', 'installed', 'free', 'operated', 'already', 'described', 'tap', 'typically', 'the', 'looking', 'finished', 'known', 'unit', 'necessary', 'mixer', 'flush', 'plug', 'connected', 'best', 'available', 'phone', 'fixed', 'used', 'hidden', 'lets', 'turning', 'usually', 'fridge', 'entitled', 'responsible', 'broken', 'coming', 'meant', 'heat', 'marked', 'essential', 'therefore', 'open', 'disconnected', 'completely', 'appliance', 'opposite', 'provided', 'taken', 'named', 'currently', 'pulled', 'fuse', 'done', 'to', 'call', 'see', 'fitting', 'replaced', 'la', 'ideal', 'using', 'temperature', 'situated', 'always', 'switched', 'ready', 'part', 'white', 'covered', 'also', 'associated', 'going', 'normally', 'generally', 'rather', 'filled', 'pump', 'exposed', 'us', 'turned', 'soft', 'important', 'knock', 'back', 'blocked', 'without', 'designed', 'le', 'inside', 'suing', 'held', 'low', 'really', 'sink', 'fan', 'lit', 'located', 'made', 'led', 'actually', 'time', 'appliances', 'equipped', 'kettle', 'valve', 'toilet', 'press', 'washer', 'shown', 'right', 'closed', 'shut', 'number', 'removed', 'water', 'switch', 'opened', 'basically', 'run', 'turn', 'required', 'powered', 'two', 'cooker', 'next', 'heating', 'mounted', 'power', 'similar', 'one', 'either', 'running', 'small', 'attached', 'boiler', 'calling', 'still', 'light', 'cut', 'name', 'equal', 'quite', 'built', 'worth', 'placed', 'due', 'indicated', 'let', 'single', 'clearly', 'sometimes', 'self', 'mentioned', 'added', 'en', 'needed', 'fitted', 'hot', 'supplied', 'given', 'main', 'easy', 'heated', 'home', 'sold', 'electric', 'intended', 'automatically', 'called', 'left', 'directly', 'probably', 'something', 'activate', 'er', 'suitable', 'simply', 'supposed', 'easily', 'exactly', 'often', 'dial', 'seen', 'listed', 'set', 'sub', 'produced', 'controlled', 'included', 'found', 'near', 'good', 'energy', 'washing'] \n",
      "\n",
      "Where do the brown animals stand on? field n497789\n",
      "\t the brown animals stand on <extra_id_0> .\n",
      "\tMine:  243 False []\n",
      "['view', 'big', 'platform', 'lower', 'pictures', 'sea', 'like', 'course', 'several', 'bronze', 'said', 'grass', 'mountain', 'new', 'another', 'well', 'large', 'free', 'milk', 'ha', 'the', 'bamboo', 'first', 'full', 'rice', 'center', 'firm', 'granite', 'river', 'sale', 'leaves', 'earth', 'pride', 'golden', 'middle', 'shelves', 'beautiful', 'trail', 'cross', 'standing', 'co', 'purpose', 'benches', 'ho', 'concrete', 'many', 'top', 'upper', 'average', 'certain', 'wild', 'tower', 'higher', 'food', 'giant', 'site', 'sight', 'yellow', 'dead', 'opposite', 'life', 'page', 'dark', 'three', 'steel', 'point', 'sticks', 'behalf', 'dry', 'iron', 'empty', 'hill', 'solid', 'colored', 'posts', 'edge', 'world', 'line', 'twitter', 'post', 'plants', 'man', 'campus', 'wooden', 'white', 'rest', 'proud', 'tree', 'board', 'various', 'base', 'islands', 'floor', 'tripod', 'us', 'shore', 'soft', 'natural', 'back', 'tall', 'green', 'balance', 'stones', 'things', 'snow', 'upright', 'head', 'hand', 'low', 'six', 'corners', 'red', 'rock', 'separate', 'ground', 'public', 'time', 'purple', 'good', 'cage', 'plant', 'branches', 'strong', 'brown', 'four', 'hard', 'blue', 'sunday', 'level', 'right', 'paper', 'summer', 'shoulders', 'old', 'hold', 'water', 'end', 'cu', 'plastic', 'five', 'huge', 'show', 'two', 'next', 'foot', 'per', 'island', 'together', 'power', 'display', 'tip', 'stand', 'day', 'side', 'flower', 'one', 'either', 'corner', 'human', 'small', 'wood', 'straw', 'every', 'wheels', 'still', 'road', 'tables', 'light', 'way', 'equal', 'bottom', 'trees', 'feet', 'wide', 'cloud', 'orange', 'round', 'color', 'real', 'legs', 'hills', 'stands', 'animals', 'stone', 'sides', 'height', 'stage', 'horse', 'rocks', 'thick', 'eggs', 'front', 'deck', 'gray', 'africa', 'account', 'animal', 'elephant', 'individual', 'land', 'star', 'special', 'silver', 'home', 'shoulder', 'table', 'extra', 'pink', 'left', 'little', 'pole', 'beach', 'something', 'egg', 'people', 'soil', 'mountains', 'bear', 'colorful', 'picture', 'flowers', 'carpet', 'place', 'track', 'chairs', 'watch', 'sun', 'everything', 'different', 'bright', 'african', 'long', 'forest', 'guard', 'fire', 'fence', 'black', 'fresh', 'sturdy', 'high', 'moon', 'farm', 'far'] \n",
      "\n",
      "Total: 11 \n",
      "\tUpper acc 45.45454545454545\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "    if vis>10:\n",
    "        break\n",
    "        \n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \n",
    "    statement=generate_statement(temp_file[row['key']])\n",
    "    t5_pred=candidate_generator(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "        \n",
    "    print (ques,answers,row['imageId'])\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\n",
    "    if vis%200==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d708f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "130b85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statement_bart(sent):\n",
    "    flag=True\n",
    "    words=[]\n",
    "    for w in sent[:-1].lower().split(' '):\n",
    "        if w =='item' and flag:\n",
    "            flag=False\n",
    "            words.append('the')\n",
    "            words.append('<mask>')\n",
    "        else:\n",
    "            words.append(w)\n",
    "    if '<mask>' not in words:\n",
    "        words.append('<mask>')\n",
    "    words.append('.')\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481e84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statement_gt(sent,ans):\n",
    "    flag=True\n",
    "    words=[]\n",
    "    for w in sent[:-1].lower().split(' '):\n",
    "        if w ==ans and flag:\n",
    "            flag=False\n",
    "            words.append('the')\n",
    "            words.append('<mask>')\n",
    "        else:\n",
    "            words.append(w)\n",
    "    words.append('.')\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1b3343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_generator_bart(statement):\n",
    "    input_ids = bart_tokenizer([statement],\n",
    "                               return_tensors=\"pt\")[\"input_ids\"]\n",
    "    logits = bart_model(input_ids.to(device)).logits\n",
    "        #print ((input_ids[0] == bart_tokenizer.mask_token_id).sum())\n",
    "    masked_index = (input_ids[0] == bart_tokenizer.mask_token_id).nonzero().item()\n",
    "    \n",
    "    probs = logits[0, masked_index].softmax(dim=0)\n",
    "    values, predictions = probs.topk(200)\n",
    "    pred=bart_tokenizer.decode(predictions).split()\n",
    "    results=list(set(pred))\n",
    "    results=process(results)\n",
    "    results=list(set(results))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbefe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a997d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 generated with generated template\n",
      "6805\n",
      "Upper acc 52.8\n",
      "Upper acc 53.075\n",
      "Upper acc 53.45\n",
      "Total: 6805 \n",
      "\tUpper acc 53.37252020573108\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "print ('T5 generated with generated template')\n",
    "total={}\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    #if vis>10:\n",
    "    #    break\n",
    "    vis+=1\n",
    "        \n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    #print (temp_file[row['key']])\n",
    "    try:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    except:\n",
    "        statement=generate_statement_gt(row['fullAnswer'],answers)\n",
    "    statement=statement.replace('<mask>',\n",
    "                                '<extra_id_0>')\n",
    "    t5_pred=candidate_generator(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "    total[row['key']]=t5_pred    \n",
    "    \"\"\"print (ques,answers,row['img'])\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\"\"\"\n",
    "    if vis%2000==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "#pkl.dump(total,open('gqa_t5_pred/t5_generated_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0025d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('gqa_t5_pred/dev_t5_generated_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "525060fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 generated with generated template\n",
      "68167\n",
      "Upper acc 63.95\n",
      "Upper acc 62.675\n",
      "Upper acc 61.45\n",
      "Upper acc 61.1\n",
      "Upper acc 60.97\n",
      "Upper acc 60.975\n",
      "Upper acc 61.15714285714286\n",
      "Upper acc 61.15625\n",
      "Upper acc 61.144444444444446\n",
      "Upper acc 61.04\n",
      "Upper acc 60.91818181818182\n",
      "Upper acc 60.90416666666667\n",
      "Upper acc 60.98461538461538\n",
      "Upper acc 60.91428571428571\n",
      "Upper acc 60.81666666666667\n",
      "Upper acc 60.821875\n",
      "Upper acc 60.794117647058826\n",
      "Upper acc 60.87222222222222\n",
      "Upper acc 60.873684210526314\n",
      "Upper acc 60.8775\n",
      "Upper acc 60.79761904761905\n",
      "Upper acc 60.80227272727273\n",
      "Upper acc 60.8304347826087\n",
      "Upper acc 60.82083333333333\n",
      "Upper acc 60.794\n",
      "Upper acc 60.86153846153846\n",
      "Upper acc 60.86296296296296\n",
      "Upper acc 60.92321428571429\n",
      "Upper acc 60.91034482758621\n",
      "Upper acc 60.92166666666667\n",
      "Upper acc 60.880645161290325\n",
      "Upper acc 60.884375\n",
      "Upper acc 60.89393939393939\n",
      "Upper acc 60.891176470588235\n",
      "Total: 68167 \n",
      "\tUpper acc 60.898968709199465\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "print ('T5 generated with generated template')\n",
    "total={}\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "        \n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \n",
    "    statement=generate_statement_bart(temp_file[row['key']]).replace('<mask>',\n",
    "                                                                     '<extra_id_0>')\n",
    "    t5_pred=candidate_generator(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "    total[row['key']]=t5_pred    \n",
    "    \"\"\"print (ques,answers,row['img'])\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\"\"\"\n",
    "    if vis%2000==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "#pkl.dump(total,open('gqa_t5_pred/t5_generated_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e98f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ccad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 generated with generated template\n",
      "68167\n",
      "Upper acc 64.5\n",
      "Upper acc 65.8\n",
      "Upper acc 65.43333333333334\n",
      "Upper acc 65.6625\n",
      "Upper acc 65.81\n",
      "Upper acc 65.71666666666667\n",
      "Upper acc 65.70714285714286\n",
      "Upper acc 65.61875\n",
      "Upper acc 65.59444444444445\n",
      "Upper acc 65.71\n",
      "Upper acc 65.68636363636364\n",
      "Upper acc 65.61666666666666\n",
      "Upper acc 65.75769230769231\n",
      "Upper acc 65.61785714285715\n",
      "Upper acc 65.62333333333333\n",
      "Upper acc 65.66875\n",
      "Upper acc 65.75588235294117\n",
      "Upper acc 65.70555555555555\n",
      "Upper acc 65.69473684210526\n",
      "Upper acc 65.66\n",
      "Upper acc 65.6452380952381\n",
      "Upper acc 65.64772727272727\n",
      "Upper acc 65.63260869565218\n",
      "Upper acc 65.67083333333333\n",
      "Upper acc 65.654\n",
      "Upper acc 65.63269230769231\n",
      "Upper acc 65.64814814814815\n",
      "Upper acc 65.67142857142858\n",
      "Upper acc 65.68448275862069\n",
      "Upper acc 65.68666666666667\n",
      "Upper acc 65.66451612903226\n",
      "Upper acc 65.6125\n",
      "Upper acc 65.58181818181818\n",
      "Upper acc 65.61764705882354\n",
      "Total: 68167 \n",
      "\tUpper acc 65.62559596285593\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "print ('T5 generated with generated template')\n",
    "total={}\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "        \n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \n",
    "    try:\n",
    "        statement=generate_statement_gt(row['full_ans'],answers)\n",
    "    except:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    if '<mask>' not in statement:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    \n",
    "    statement=statement.replace('<mask>',\n",
    "                                '<extra_id_0>')\n",
    "    t5_pred=candidate_generator(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "    total[row['key']]=t5_pred    \n",
    "    \"\"\"print (ques,answers,row['img'])\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\"\"\"\n",
    "    if vis%2000==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "pkl.dump(total,open('gqa_t5_pred/t5_gt_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88891b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bart\n",
      "Using ground truth template\n",
      "68167\n",
      "Upper acc 51.4\n",
      "Upper acc 50.725\n",
      "Upper acc 50.86666666666667\n",
      "Upper acc 49.9875\n",
      "Upper acc 49.86\n",
      "Upper acc 49.891666666666666\n",
      "Upper acc 49.99285714285714\n",
      "Upper acc 49.70625\n",
      "Upper acc 49.65555555555556\n",
      "Upper acc 49.735\n",
      "Upper acc 49.872727272727275\n",
      "Upper acc 49.925\n",
      "Upper acc 49.86153846153846\n",
      "Upper acc 49.714285714285715\n",
      "Upper acc 49.79\n",
      "Upper acc 49.878125\n",
      "Upper acc 49.88823529411765\n",
      "Upper acc 49.9\n",
      "Upper acc 49.95\n",
      "Upper acc 49.9875\n",
      "Upper acc 49.99047619047619\n",
      "Upper acc 49.89772727272727\n",
      "Upper acc 49.93478260869565\n",
      "Upper acc 49.927083333333336\n",
      "Upper acc 49.892\n",
      "Upper acc 49.80384615384615\n",
      "Upper acc 49.803703703703704\n",
      "Upper acc 49.75535714285714\n",
      "Upper acc 49.72586206896552\n",
      "Upper acc 49.735\n",
      "Upper acc 49.730645161290326\n",
      "Upper acc 49.8046875\n",
      "Upper acc 49.8\n",
      "Upper acc 49.826470588235296\n",
      "Total: 68167 \n",
      "\tUpper acc 49.82909619023868\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "print ('Using bart')\n",
    "print ('Using ground truth template')\n",
    "#random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "total={}\n",
    "flag=True\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    try:\n",
    "        statement=generate_statement_gt(row['full_ans'],answers)\n",
    "    except:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    if '<mask>' not in statement:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    \n",
    "    t5_pred=candidate_generator_bart(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "        \n",
    "    \"\"\"print (ques,answers,row['img'])\n",
    "    print ('\\t',row['full_ans'].lower().replace(row['answer'],'<mask>'))\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\"\"\"\n",
    "    total[row['key']]=t5_pred\n",
    "    if vis%2000==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "pkl.dump(total,open('gqa_t5_pred/bart_gt_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5707b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bart\n",
      "Using generated template\n",
      "68167\n",
      "Upper acc 47.65\n",
      "Upper acc 47.85\n",
      "Upper acc 47.416666666666664\n",
      "Upper acc 47.375\n",
      "Upper acc 47.42\n",
      "Upper acc 47.75833333333333\n",
      "Upper acc 47.871428571428574\n",
      "Upper acc 47.7875\n",
      "Upper acc 47.56666666666667\n",
      "Upper acc 47.56\n",
      "Upper acc 47.413636363636364\n",
      "Upper acc 47.34166666666667\n",
      "Upper acc 47.41153846153846\n",
      "Upper acc 47.38214285714286\n",
      "Upper acc 47.46666666666667\n",
      "Upper acc 47.4375\n",
      "Upper acc 47.370588235294115\n",
      "Upper acc 47.57222222222222\n",
      "Upper acc 47.48684210526316\n",
      "Upper acc 47.5825\n",
      "Upper acc 47.58571428571429\n",
      "Upper acc 47.472727272727276\n",
      "Upper acc 47.54347826086956\n",
      "Upper acc 47.55416666666667\n",
      "Upper acc 47.618\n",
      "Upper acc 47.59230769230769\n",
      "Upper acc 47.6462962962963\n",
      "Upper acc 47.6375\n",
      "Upper acc 47.601724137931036\n",
      "Upper acc 47.696666666666665\n",
      "Upper acc 47.73548387096774\n",
      "Upper acc 47.7515625\n",
      "Upper acc 47.7469696969697\n",
      "Upper acc 47.78235294117647\n",
      "Total: 68167 \n",
      "\tUpper acc 47.787052386051904\n"
     ]
    }
   ],
   "source": [
    "q_t='query'\n",
    "vis=0\n",
    "upper=0.0\n",
    "showing=True\n",
    "print ('Using bart')\n",
    "print ('Using generated template')\n",
    "random.shuffle(val_based_qt[q_t])\n",
    "acc=0.0\n",
    "upper_acc=0.0\n",
    "total={}\n",
    "print(len(val_based_qt[q_t]))\n",
    "for row in val_based_qt[q_t]:\n",
    "    vis+=1\n",
    "    \n",
    "    answers=row['answer']\n",
    "    ques=row['question']\n",
    "    \"\"\"try:\n",
    "        statement=row['full_ans'][:-1].lower().replace(row['answer'],'<mask>')\n",
    "    except:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\n",
    "    if '<mask>' not in statement:\n",
    "        statement=generate_statement_bart(temp_file[row['key']])\"\"\"\n",
    "    #print ('\\t',statement)\n",
    "    statement=generate_statement_bart(temp_file[row['key']])\n",
    "    t5_pred=candidate_generator_bart(statement)\n",
    "    \n",
    "    upper,in_list=verify_ans([row['answer']],t5_pred)\n",
    "    if upper:\n",
    "        upper_acc+=1\n",
    "        \n",
    "    \"\"\"print (ques,answers,row['img'])\n",
    "    print ('\\t',row['full_ans'].lower().replace(row['answer'],'<mask>'))\n",
    "    print ('\\t',statement)\n",
    "    print ('\\tMine: ',len(t5_pred),upper,in_list)\n",
    "    print (\n",
    "        t5_pred,\n",
    "        '\\n')\"\"\"\n",
    "    total[row['key']]=t5_pred\n",
    "    if vis%2000==0:\n",
    "        print ('Upper acc',upper_acc*100.0/vis)\n",
    "print ('Total:',vis,'\\n\\tUpper acc',upper_acc*100.0/vis)\n",
    "pkl.dump(total,open('gqa_t5_pred/bart_generated_temp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9bb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e14bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
